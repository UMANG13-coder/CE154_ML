{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UMANG13-coder/CE154_ML/blob/main/Lab_7/Lab_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "K5g7Vwjo0tei",
        "outputId": "f80560c8-30f5-43ac-d65d-811d49116a96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "Round: 0 Weight: [0.03058166 0.0185155 ] Bias: 0.18323088598303794\n",
            "Round: 1 Weight: [0.06032602 0.03644115] Bias: 0.16687886637910004\n",
            "Round: 2 Weight: [0.08925577 0.05379538] Bias: 0.1509369328570195\n",
            "Round: 3 Weight: [0.11739458 0.0705972 ] Bias: 0.13539722343869307\n",
            "Round: 4 Weight: [0.14476677 0.08686595] Bias: 0.12025116762719985\n",
            "Round: 5 Weight: [0.17139707 0.10262113] Bias: 0.10548962517106947\n",
            "Round: 6 Weight: [0.1973104 0.1178822] Bias: 0.09110301575659821\n",
            "Round: 7 Weight: [0.22253164 0.13266848] Bias: 0.07708143779768806\n",
            "Round: 8 Weight: [0.24708544 0.14699897] Bias: 0.06341477526512351\n",
            "Round: 9 Weight: [0.27099613 0.1608923 ] Bias: 0.05009279214101791\n",
            "Round: 10 Weight: [0.29428756 0.17436659] Bias: 0.03710521459299888\n",
            "Round: 11 Weight: [0.31698301 0.18743947] Bias: 0.024441801342511595\n",
            "Round: 12 Weight: [0.3391051  0.20012795] Bias: 0.01209240296611777\n",
            "Round: 13 Weight: [0.36067579 0.21244843] Bias: 4.7011035559195793e-05\n",
            "Round: 14 Weight: [0.38171626 0.22441669] Bias: -0.011704201909513262\n",
            "Round: 15 Weight: [0.40224695 0.23604786] Bias: -0.023170850534799572\n",
            "Round: 16 Weight: [0.42228754 0.24735641] Bias: -0.034362312026343815\n",
            "Round: 17 Weight: [0.4418569  0.25835618] Bias: -0.04528770759094464\n",
            "Round: 18 Weight: [0.46097313 0.26906036] Bias: -0.05595588925336222\n",
            "Round: 19 Weight: [0.47965359 0.27948156] Bias: -0.06637543114051557\n",
            "Round: 20 Weight: [0.49791485 0.28963174] Bias: -0.07655462452633155\n",
            "Round: 21 Weight: [0.51577278 0.29952232] Bias: -0.08650147599438897\n",
            "Round: 22 Weight: [0.53324254 0.30916414] Bias: -0.09622370815583259\n",
            "Round: 23 Weight: [0.55033857 0.31856751] Bias: -0.10572876243519887\n",
            "Round: 24 Weight: [0.5670747  0.32774223] Bias: -0.11502380350564935\n",
            "Round: 25 Weight: [0.5834641  0.33669761] Bias: -0.12411572501713283\n",
            "Round: 26 Weight: [0.59951932 0.3454425 ] Bias: -0.13301115631611987\n",
            "Round: 27 Weight: [0.61525236 0.35398529] Bias: -0.14171646990399703\n",
            "Round: 28 Weight: [0.63067465 0.36233396] Bias: -0.1502377894233838\n",
            "Round: 29 Weight: [0.64579709 0.37049609] Bias: -0.1585809979980568\n",
            "Round: 30 Weight: [0.66063009 0.3784789 ] Bias: -0.16675174678339877\n",
            "Round: 31 Weight: [0.67518356 0.38628921] Bias: -0.17475546361090433\n",
            "Round: 32 Weight: [0.689467   0.39393355] Bias: -0.18259736163282475\n",
            "Round: 33 Weight: [0.70348942 0.4014181 ] Bias: -0.19028244789203916\n",
            "Round: 34 Weight: [0.71725947 0.40874875] Bias: -0.19781553175817737\n",
            "Round: 35 Weight: [0.73078538 0.4159311 ] Bias: -0.2052012331843185\n",
            "Round: 36 Weight: [0.74407504 0.42297047] Bias: -0.21244399074963222\n",
            "Round: 37 Weight: [0.75713596 0.42987195] Bias: -0.21954806946245278\n",
            "Round: 38 Weight: [0.76997533 0.43664036] Bias: -0.22651756830577208\n",
            "Round: 39 Weight: [0.78260005 0.44328032] Bias: -0.23335642751326266\n",
            "Round: 40 Weight: [0.79501668 0.44979622] Bias: -0.24006843556891128\n",
            "Round: 41 Weight: [0.80723153 0.45619224] Bias: -0.24665723592734717\n",
            "Round: 42 Weight: [0.81925063 0.46247238] Bias: -0.2531263334551463\n",
            "Round: 43 Weight: [0.83107975 0.46864046] Bias: -0.2594791005959171\n",
            "Round: 44 Weight: [0.84272442 0.47470013] Bias: -0.26571878326394244\n",
            "Round: 45 Weight: [0.85418996 0.48065485] Bias: -0.27184850647265996\n",
            "Round: 46 Weight: [0.86548144 0.48650797] Bias: -0.27787127970539366\n",
            "Round: 47 Weight: [0.87660374 0.49226265] Bias: -0.2837900020365688\n",
            "Round: 48 Weight: [0.88756156 0.49792195] Bias: -0.28960746701220846\n",
            "Round: 49 Weight: [0.89835939 0.50348877] Bias: -0.2953263672988732\n",
            "Round: 50 Weight: [0.90900155 0.50896591] Bias: -0.3009492991103991\n",
            "Round: 51 Weight: [0.91949218 0.51435604] Bias: -0.30647876642185595\n",
            "Round: 52 Weight: [0.92983529 0.51966171] Bias: -0.3119171849801045\n",
            "Round: 53 Weight: [0.9400347 0.5248854] Bias: -0.3172668861202097\n",
            "Round: 54 Weight: [0.95009412 0.53002943] Bias: -0.3225301203967804\n",
            "Round: 55 Weight: [0.96001709 0.53509609] Bias: -0.3277090610390711\n",
            "Round: 56 Weight: [0.96980704 0.54008754] Bias: -0.33280580723841197\n",
            "Round: 57 Weight: [0.97946726 0.54500585] Bias: -0.33782238727623753\n",
            "Round: 58 Weight: [0.98900093 0.54985304] Bias: -0.34276076150067364\n",
            "Round: 59 Weight: [0.99841112 0.55463102] Bias: -0.3476228251593183\n",
            "Round: 60 Weight: [1.00770078 0.55934165] Bias: -0.3524104110955277\n",
            "Round: 61 Weight: [1.01687275 0.56398671] Bias: -0.35712529231518825\n",
            "Round: 62 Weight: [1.02592979 0.56856791] Bias: -0.36176918443063466\n",
            "Round: 63 Weight: [1.03487455 0.57308689] Bias: -0.36634374798805125\n",
            "Round: 64 Weight: [1.04370959 0.57754525] Bias: -0.37085059068438586\n",
            "Round: 65 Weight: [1.0524374  0.58194451] Bias: -0.3752912694795008\n",
            "Round: 66 Weight: [1.06106037 0.58628616] Bias: -0.37966729260899457\n",
            "Round: 67 Weight: [1.06958081 0.5905716 ] Bias: -0.38398012150284566\n",
            "Round: 68 Weight: [1.07800096 0.59480221] Bias: -0.38823117261476037\n",
            "Round: 69 Weight: [1.08632298 0.59897932] Bias: -0.39242181916684776\n",
            "Round: 70 Weight: [1.09454898 0.6031042 ] Bias: -0.3965533928139979\n",
            "Round: 71 Weight: [1.10268099 0.60717809] Bias: -0.4006271852321045\n",
            "Round: 72 Weight: [1.11072096 0.61120217] Bias: -0.40464444963404994\n",
            "Round: 73 Weight: [1.1186708  0.61517759] Bias: -0.4086064022171563\n",
            "Round: 74 Weight: [1.12653236 0.61910546] Bias: -0.4125142235456063\n",
            "Round: 75 Weight: [1.13430743 0.62298687] Bias: -0.4163690598711465\n",
            "Round: 76 Weight: [1.14199774 0.62682285] Bias: -0.42017202439520285\n",
            "Round: 77 Weight: [1.14960498 0.6306144 ] Bias: -0.4239241984753696\n",
            "Round: 78 Weight: [1.15713076 0.6343625 ] Bias: -0.4276266327790688\n",
            "Round: 79 Weight: [1.16457669 0.63806809] Bias: -0.4312803483870265\n",
            "Round: 80 Weight: [1.17194429 0.64173209] Bias: -0.4348863378490656\n",
            "Round: 81 Weight: [1.17923507 0.64535536] Bias: -0.43844556619458086\n",
            "Round: 82 Weight: [1.18645046 0.64893878] Bias: -0.4419589718999311\n",
            "Round: 83 Weight: [1.19359188 0.65248317] Bias: -0.44542746781486364\n",
            "Round: 84 Weight: [1.2006607  0.65598933] Bias: -0.4488519420499708\n",
            "Round: 85 Weight: [1.20765825 0.65945804] Bias: -0.4522332588270708\n",
            "Round: 86 Weight: [1.21458582 0.66289007] Bias: -0.4555722592943031\n",
            "Round: 87 Weight: [1.22144468 0.66628613] Bias: -0.4588697623076322\n",
            "Round: 88 Weight: [1.22823605 0.66964696] Bias: -0.46212656518036443\n",
            "Round: 89 Weight: [1.23496111 0.67297322] Bias: -0.46534344440219505\n",
            "Round: 90 Weight: [1.24162104 0.67626561] Bias: -0.46852115632922436\n",
            "Round: 91 Weight: [1.24821695 0.67952476] Bias: -0.4716604378463042\n",
            "Round: 92 Weight: [1.25474996 0.68275132] Bias: -0.4747620070030053\n",
            "Round: 93 Weight: [1.26122113 0.68594589] Bias: -0.4778265636244289\n",
            "Round: 94 Weight: [1.2676315  0.68910907] Bias: -0.4808547898980204\n",
            "Round: 95 Weight: [1.27398209 0.69224146] Bias: -0.48384735093748565\n",
            "Round: 96 Weight: [1.2802739 0.6953436] Bias: -0.48680489532485116\n",
            "Round: 97 Weight: [1.28650788 0.69841605] Bias: -0.4897280556316573\n",
            "Round: 98 Weight: [1.29268499 0.70145936] Bias: -0.49261744892022286\n",
            "Round: 99 Weight: [1.29880614 0.70447402] Bias: -0.4954736772258717\n",
            "Round: 100 Weight: [1.30487223 0.70746056] Bias: -0.4982973280209667\n",
            "Round: 101 Weight: [1.31088413 0.71041947] Bias: -0.5010889746615543\n",
            "Round: 102 Weight: [1.3168427  0.71335122] Bias: -0.5038491768173825\n",
            "Round: 103 Weight: [1.32274877 0.71625628] Bias: -0.5065784808860173\n",
            "Round: 104 Weight: [1.32860315 0.71913512] Bias: -0.5092774203917464\n",
            "Round: 105 Weight: [1.33440664 0.72198817] Bias: -0.5119465163699248\n",
            "Round: 106 Weight: [1.34016002 0.72481586] Bias: -0.5145862777373869\n",
            "Round: 107 Weight: [1.34586405 0.72761862] Bias: -0.5171972016495157\n",
            "Round: 108 Weight: [1.35151946 0.73039686] Bias: -0.5197797738445348\n",
            "Round: 109 Weight: [1.35712697 0.73315097] Bias: -0.5223344689755588\n",
            "Round: 110 Weight: [1.36268731 0.73588136] Bias: -0.5248617509309141\n",
            "Round: 111 Weight: [1.36820115 0.7385884 ] Bias: -0.5273620731432161\n",
            "Round: 112 Weight: [1.37366918 0.74127246] Bias: -0.5298358788876673\n",
            "Round: 113 Weight: [1.37909206 0.74393391] Bias: -0.532283601570017\n",
            "Round: 114 Weight: [1.38447043 0.7465731 ] Bias: -0.5347056650046058\n",
            "Round: 115 Weight: [1.38980493 0.74919038] Bias: -0.5371024836828939\n",
            "Round: 116 Weight: [1.39509618 0.75178608] Bias: -0.5394744630328582\n",
            "Round: 117 Weight: [1.40034478 0.75436054] Bias: -0.5418219996696223\n",
            "Round: 118 Weight: [1.40555133 0.75691408] Bias: -0.5441454816376691\n",
            "Round: 119 Weight: [1.4107164 0.759447 ] Bias: -0.5464452886449676\n",
            "Round: 120 Weight: [1.41584057 0.76195963] Bias: -0.5487217922893324\n",
            "Round: 121 Weight: [1.4209244  0.76445225] Bias: -0.550975356277319\n",
            "Round: 122 Weight: [1.42596842 0.76692517] Bias: -0.5532063366359441\n",
            "Round: 123 Weight: [1.43097318 0.76937867] Bias: -0.5554150819175095\n",
            "Round: 124 Weight: [1.4359392  0.77181304] Bias: -0.557601933397792\n",
            "Round: 125 Weight: [1.44086698 0.77422854] Bias: -0.5597672252678536\n",
            "Round: 126 Weight: [1.44575704 0.77662544] Bias: -0.5619112848197146\n",
            "Round: 127 Weight: [1.45060986 0.77900402] Bias: -0.5640344326261189\n",
            "Round: 128 Weight: [1.45542593 0.78136451] Bias: -0.5661369827146143\n",
            "Round: 129 Weight: [1.46020573 0.78370719] Bias: -0.5682192427361605\n",
            "Round: 130 Weight: [1.46494971 0.78603229] Bias: -0.570281514128465\n",
            "Round: 131 Weight: [1.46965833 0.78834005] Bias: -0.572324092274243\n",
            "Round: 132 Weight: [1.47433203 0.79063071] Bias: -0.5743472666545874\n",
            "Round: 133 Weight: [1.47897127 0.7929045 ] Bias: -0.5763513209976255\n",
            "Round: 134 Weight: [1.48357646 0.79516165] Bias: -0.5783365334226347\n",
            "Round: 135 Weight: [1.48814802 0.79740238] Bias: -0.5803031765797786\n",
            "Round: 136 Weight: [1.49268638 0.7996269 ] Bias: -0.582251517785623\n",
            "Round: 137 Weight: [1.49719194 0.80183543] Bias: -0.5841818191545802\n",
            "Round: 138 Weight: [1.50166509 0.80402817] Bias: -0.5860943377264259\n",
            "Round: 139 Weight: [1.50610623 0.80620534] Bias: -0.5879893255900277\n",
            "Round: 140 Weight: [1.51051574 0.80836713] Bias: -0.5898670300034172\n",
            "Round: 141 Weight: [1.51489399 0.81051373] Bias: -0.591727693510334\n",
            "Round: 142 Weight: [1.51924137 0.81264534] Bias: -0.5935715540533623\n",
            "Round: 143 Weight: [1.52355823 0.81476215] Bias: -0.5953988450837784\n",
            "Round: 144 Weight: [1.52784493 0.81686433] Bias: -0.5972097956682229\n",
            "Round: 145 Weight: [1.53210182 0.81895209] Bias: -0.5990046305923028\n",
            "Round: 146 Weight: [1.53632925 0.82102558] Bias: -0.600783570461231\n",
            "Round: 147 Weight: [1.54052755 0.82308498] Bias: -0.6025468317976003\n",
            "Round: 148 Weight: [1.54469706 0.82513048] Bias: -0.6042946271363897\n",
            "Round: 149 Weight: [1.54883811 0.82716222] Bias: -0.6060271651172953\n",
            "Round: 150 Weight: [1.55295101 0.82918039] Bias: -0.6077446505744728\n",
            "Round: 151 Weight: [1.55703609 0.83118513] Bias: -0.6094472846237796\n",
            "Round: 152 Weight: [1.56109365 0.83317661] Bias: -0.6111352647475969\n",
            "Round: 153 Weight: [1.565124   0.83515499] Bias: -0.612808784877311\n",
            "Round: 154 Weight: [1.56912744 0.83712041] Bias: -0.6144680354735307\n",
            "Round: 155 Weight: [1.57310427 0.83907303] Bias: -0.6161132036041131\n",
            "Round: 156 Weight: [1.57705477 0.841013  ] Bias: -0.6177444730200696\n",
            "Round: 157 Weight: [1.58097924 0.84294045] Bias: -0.6193620242294177\n",
            "Round: 158 Weight: [1.58487796 0.84485554] Bias: -0.6209660345690464\n",
            "Round: 159 Weight: [1.58875119 0.84675839] Bias: -0.6225566782746573\n",
            "Round: 160 Weight: [1.59259922 0.84864916] Bias: -0.6241341265488412\n",
            "Round: 161 Weight: [1.59642231 0.85052797] Bias: -0.6256985476273494\n",
            "Round: 162 Weight: [1.60022072 0.85239495] Bias: -0.6272501068436176\n",
            "Round: 163 Weight: [1.60399472 0.85425024] Bias: -0.6287889666915929\n",
            "Round: 164 Weight: [1.60774456 0.85609396] Bias: -0.6303152868869203\n",
            "Round: 165 "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-14-ab0998c957e9>:65: RuntimeWarning: divide by zero encountered in log\n",
            "  total_bce_loss = np.sum(-y * np.log(y1) - (1 - y) * np.log(1 - y1))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weight: [1.61147049 0.85792624] Bias: -0.6318292244265371\n",
            "Round: 166 Weight: [1.61517276 0.85974721] Bias: -0.633330933646724\n",
            "Round: 167 Weight: [1.61885161 0.86155698] Bias: -0.6348205662796605\n",
            "Round: 168 Weight: [1.62250729 0.86335567] Bias: -0.63629827150853\n",
            "Round: 169 Weight: [1.62614002 0.86514341] Bias: -0.6377641960212174\n",
            "Round: 170 Weight: [1.62975005 0.8669203 ] Bias: -0.6392184840626427\n",
            "Round: 171 Weight: [1.6333376  0.86868646] Bias: -0.640661277485771\n",
            "Round: 172 Weight: [1.63690289 0.87044201] Bias: -0.642092715801337\n",
            "Round: 173 Weight: [1.64044615 0.87218705] Bias: -0.6435129362263249\n",
            "Round: 174 Weight: [1.6439676  0.87392169] Bias: -0.6449220737312371\n",
            "Round: 175 Weight: [1.64746745 0.87564603] Bias: -0.6463202610861895\n",
            "Round: 176 Weight: [1.65094592 0.87736019] Bias: -0.6477076289058666\n",
            "Round: 177 Weight: [1.65440322 0.87906427] Bias: -0.649084305693371\n",
            "Round: 178 Weight: [1.65783954 0.88075836] Bias: -0.6504504178829964\n",
            "Round: 179 Weight: [1.66125511 0.88244256] Bias: -0.6518060898819581\n",
            "Round: 180 Weight: [1.6646501  0.88411699] Bias: -0.6531514441111098\n",
            "Round: 181 Weight: [1.66802474 0.88578172] Bias: -0.6544866010446748\n",
            "Round: 182 Weight: [1.6713792  0.88743686] Bias: -0.6558116792490208\n",
            "Round: 183 Weight: [1.67471368 0.8890825 ] Bias: -0.6571267954205048\n",
            "Round: 184 Weight: [1.67802836 0.89071873] Bias: -0.6584320644224144\n",
            "Round: 185 Weight: [1.68132345 0.89234565] Bias: -0.6597275993210309\n",
            "Round: 186 Weight: [1.68459912 0.89396334] Bias: -0.6610135114208384\n",
            "Round: 187 Weight: [1.68785554 0.89557189] Bias: -0.6622899102989033\n",
            "Round: 188 Weight: [1.69109291 0.89717139] Bias: -0.6635569038384463\n",
            "Round: 189 Weight: [1.69431139 0.89876193] Bias: -0.6648145982616301\n",
            "Round: 190 Weight: [1.69751117 0.90034358] Bias: -0.6660630981615832\n",
            "Round: 191 Weight: [1.70069241 0.90191644] Bias: -0.6673025065336817\n",
            "Round: 192 Weight: [1.70385527 0.90348057] Bias: -0.6685329248061095\n",
            "Round: 193 Weight: [1.70699994 0.90503608] Bias: -0.6697544528697139\n",
            "Round: 194 Weight: [1.71012657 0.90658302] Bias: -0.6709671891071801\n",
            "Round: 195 Weight: [1.71323533 0.90812149] Bias: -0.672171230421538\n",
            "Round: 196 Weight: [1.71632638 0.90965156] Bias: -0.6733666722640232\n",
            "Round: 197 Weight: [1.71939987 0.91117331] Bias: -0.6745536086613069\n",
            "Round: 198 Weight: [1.72245596 0.9126868 ] Bias: -0.6757321322421118\n",
            "Round: 199 Weight: [1.7254948  0.91419212] Bias: -0.6769023342632321\n",
            "Round: 200 Weight: [1.72851656 0.91568934] Bias: -0.6780643046349704\n",
            "Round: 201 Weight: [1.73152137 0.91717852] Bias: -0.6792181319460089\n",
            "Round: 202 Weight: [1.73450938 0.91865975] Bias: -0.680363903487729\n",
            "Round: 203 Weight: [1.73748075 0.92013309] Bias: -0.6815017052779935\n",
            "Round: 204 Weight: [1.74043562 0.92159861] Bias: -0.6826316220844051\n",
            "Round: 205 Weight: [1.74337412 0.92305637] Bias: -0.683753737447056\n",
            "Round: 206 Weight: [1.74629641 0.92450645] Bias: -0.6848681337007796\n",
            "Round: 207 Weight: [1.74920261 0.92594891] Bias: -0.6859748919969186\n",
            "Round: 208 Weight: [1.75209287 0.92738382] Bias: -0.6870740923246218\n",
            "Round: 209 Weight: [1.75496731 0.92881123] Bias: -0.6881658135316804\n",
            "Round: 210 Weight: [1.75782609 0.93023123] Bias: -0.6892501333449166\n",
            "Round: 211 Weight: [1.76066932 0.93164386] Bias: -0.6903271283901352\n",
            "Round: 212 Weight: [1.76349714 0.93304918] Bias: -0.6913968742116493\n",
            "Round: 213 Weight: [1.76630967 0.93444727] Bias: -0.6924594452913909\n",
            "Round: 214 Weight: [1.76910705 0.93583818] Bias: -0.6935149150676164\n",
            "Round: 215 Weight: [1.7718894  0.93722197] Bias: -0.6945633559532173\n",
            "Round: 216 Weight: [1.77465684 0.9385987 ] Bias: -0.6956048393536455\n",
            "Round: 217 Weight: [1.7774095  0.93996842] Bias: -0.6966394356844636\n",
            "Round: 218 Weight: [1.7801475 0.9413312] Bias: -0.6976672143885282\n",
            "Round: 219 Weight: [1.78287095 0.94268709] Bias: -0.6986882439528158\n",
            "Round: 220 Weight: [1.78557998 0.94403614] Bias: -0.6997025919249001\n",
            "Round: 221 Weight: [1.7882747  0.94537842] Bias: -0.7007103249290888\n",
            "Round: 222 Weight: [1.79095523 0.94671397] Bias: -0.7017115086822282\n",
            "Round: 223 Weight: [1.79362168 0.94804285] Bias: -0.702706208009184\n",
            "Round: 224 Weight: [1.79627416 0.94936512] Bias: -0.7036944868580056\n",
            "Round: 225 Weight: [1.7989128  0.95068081] Bias: -0.7046764083147811\n",
            "Round: 226 Weight: [1.80153769 0.95199   ] Bias: -0.7056520346181918\n",
            "Round: 227 Weight: [1.80414894 0.95329272] Bias: -0.7066214271737719\n",
            "Round: 228 Weight: [1.80674667 0.95458904] Bias: -0.7075846465678801\n",
            "Round: 229 Weight: [1.80933097 0.95587899] Bias: -0.7085417525813926\n",
            "Round: 230 Weight: [1.81190197 0.95716263] Bias: -0.7094928042031198\n",
            "Round: 231 Weight: [1.81445975 0.95844   ] Bias: -0.7104378596429568\n",
            "Round: 232 Weight: [1.81700442 0.95971116] Bias: -0.7113769763447725\n",
            "Round: 233 Weight: [1.81953608 0.96097615] Bias: -0.7123102109990428\n",
            "Round: 234 Weight: [1.82205484 0.96223502] Bias: -0.7132376195552348\n",
            "Round: 235 Weight: [1.82456079 0.96348781] Bias: -0.7141592572339474\n",
            "Round: 236 Weight: [1.82705404 0.96473458] Bias: -0.7150751785388132\n",
            "Round: 237 Weight: [1.82953467 0.96597536] Bias: -0.7159854372681693\n",
            "Round: 238 Weight: [1.83200278 0.9672102 ] Bias: -0.716890086526499\n",
            "Round: 239 Weight: [1.83445847 0.96843915] Bias: -0.7177891787356524\n",
            "Round: 240 Weight: [1.83690184 0.96966225] Bias: -0.71868276564585\n",
            "Round: 241 Weight: [1.83933297 0.97087954] Bias: -0.7195708983464734\n",
            "Round: 242 Weight: [1.84175196 0.97209107] Bias: -0.7204536272766493\n",
            "Round: 243 Weight: [1.8441589  0.97329687] Bias: -0.7213310022356305\n",
            "Round: 244 Weight: [1.84655388 0.97449699] Bias: -0.7222030723929782\n",
            "Round: 245 Weight: [1.84893699 0.97569147] Bias: -0.7230698862985511\n",
            "Round: 246 Weight: [1.85130831 0.97688036] Bias: -0.7239314918923048\n",
            "Round: 247 Weight: [1.85366793 0.97806369] Bias: -0.7247879365139056\n",
            "Round: 248 Weight: [1.85601594 0.97924149] Bias: -0.7256392669121636\n",
            "Round: 249 Weight: [1.85835243 0.98041382] Bias: -0.726485529254288\n",
            "Round: 250 Weight: [1.86067747 0.98158071] Bias: -0.727326769134969\n",
            "Round: 251 Weight: [1.86299115 0.9827422 ] Bias: -0.7281630315852908\n",
            "Round: 252 Weight: [1.86529356 0.98389833] Bias: -0.7289943610814781\n",
            "Round: 253 Weight: [1.86758478 0.98504913] Bias: -0.7298208015534801\n",
            "Round: 254 Weight: [1.86986488 0.98619464] Bias: -0.7306423963933966\n",
            "Round: 255 Weight: [1.87213394 0.98733491] Bias: -0.7314591884637479\n",
            "Round: 256 Weight: [1.87439205 0.98846996] Bias: -0.732271220105593\n",
            "Round: 257 Weight: [1.87663929 0.98959983] Bias: -0.7330785331464987\n",
            "Round: 258 Weight: [1.87887572 0.99072456] Bias: -0.733881168908364\n",
            "Round: 259 Weight: [1.88110143 0.99184418] Bias: -0.7346791682151006\n",
            "Round: 260 Weight: [1.8833165  0.99295873] Bias: -0.7354725714001755\n",
            "Round: 261 Weight: [1.88552099 0.99406825] Bias: -0.7362614183140157\n",
            "Round: 262 Weight: [1.88771499 0.99517276] Bias: -0.7370457483312798\n",
            "Round: 263 Weight: [1.88989856 0.9962723 ] Bias: -0.7378256003579992\n",
            "Round: 264 Weight: [1.89207178 0.99736691] Bias: -0.7386010128385904\n",
            "Round: 265 Weight: [1.89423473 0.99845662] Bias: -0.7393720237627424\n",
            "Round: 266 Weight: [1.89638746 0.99954146] Bias: -0.7401386706721811\n",
            "Round: 267 Weight: [1.89853006 1.00062146] Bias: -0.7409009906673133\n",
            "Round: 268 Weight: [1.90066259 1.00169666] Bias: -0.7416590204137533\n",
            "Round: 269 Weight: [1.90278512 1.00276708] Bias: -0.7424127961487339\n",
            "Round: 270 Weight: [1.90489773 1.00383277] Bias: -0.7431623536874042\n",
            "Round: 271 Weight: [1.90700047 1.00489375] Bias: -0.7439077284290175\n",
            "Round: 272 Weight: [1.90909342 1.00595004] Bias: -0.7446489553630096\n",
            "Round: 273 Weight: [1.91117664 1.0070017 ] Bias: -0.745386069074972\n",
            "Round: 274 Weight: [1.91325021 1.00804873] Bias: -0.7461191037525208\n",
            "Round: 275 Weight: [1.91531417 1.00909118] Bias: -0.7468480931910633\n",
            "Round: 276 Weight: [1.9173686  1.01012907] Bias: -0.7475730707994649\n",
            "Round: 277 Weight: [1.91941357 1.01116243] Bias: -0.7482940696056186\n",
            "Round: 278 Weight: [1.92144913 1.01219129] Bias: -0.7490111222619179\n",
            "Round: 279 Weight: [1.92347535 1.01321568] Bias: -0.749724261050636\n",
            "Round: 280 Weight: [1.92549229 1.01423563] Bias: -0.7504335178892134\n",
            "Round: 281 Weight: [1.92750001 1.01525117] Bias: -0.7511389243354543\n",
            "Round: 282 Weight: [1.92949858 1.01626232] Bias: -0.7518405115926352\n",
            "Round: 283 Weight: [1.93148805 1.01726912] Bias: -0.752538310514527\n",
            "Round: 284 Weight: [1.93346848 1.01827159] Bias: -0.7532323516103311\n",
            "Round: 285 Weight: [1.93543994 1.01926975] Bias: -0.7539226650495331\n",
            "Round: 286 Weight: [1.93740248 1.02026364] Bias: -0.7546092806666744\n",
            "Round: 287 Weight: [1.93935615 1.02125328] Bias: -0.755292227966044\n",
            "Round: 288 Weight: [1.94130103 1.0222387 ] Bias: -0.755971536126291\n",
            "Round: 289 Weight: [1.94323716 1.02321992] Bias: -0.756647234004961\n",
            "Round: 290 Weight: [1.9451646  1.02419697] Bias: -0.7573193501429567\n",
            "Round: 291 Weight: [1.94708341 1.02516988] Bias: -0.757987912768924\n",
            "Round: 292 Weight: [1.94899364 1.02613866] Bias: -0.7586529498035659\n",
            "Round: 293 Weight: [1.95089535 1.02710336] Bias: -0.7593144888638853\n",
            "Round: 294 Weight: [1.95278859 1.02806398] Bias: -0.7599725572673576\n",
            "Round: 295 Weight: [1.95467341 1.02902057] Bias: -0.7606271820360344\n",
            "Round: 296 Weight: [1.95654988 1.02997313] Bias: -0.7612783899005814\n",
            "Round: 297 Weight: [1.95841804 1.0309217 ] Bias: -0.7619262073042485\n",
            "Round: 298 Weight: [1.96027795 1.03186629] Bias: -0.7625706604067769\n",
            "Round: 299 Weight: [1.96212965 1.03280695] Bias: -0.7632117750882411\n",
            "Round: 300 Weight: [1.9639732  1.03374367] Bias: -0.7638495769528302\n",
            "Round: 301 Weight: [1.96580865 1.0346765 ] Bias: -0.764484091332567\n",
            "Round: 302 Weight: [1.96763605 1.03560545] Bias: -0.7651153432909676\n",
            "Round: 303 Weight: [1.96945546 1.03653055] Bias: -0.7657433576266424\n",
            "Round: 304 Weight: [1.97126691 1.03745182] Bias: -0.7663681588768383\n",
            "Round: 305 Weight: [1.97307047 1.03836928] Bias: -0.7669897713209258\n",
            "Round: 306 Weight: [1.97486617 1.03928295] Bias: -0.7676082189838294\n",
            "Round: 307 Weight: [1.97665407 1.04019286] Bias: -0.7682235256394032\n",
            "Round: 308 Weight: [1.97843422 1.04109903] Bias: -0.7688357148137546\n",
            "Round: 309 Weight: [1.98020666 1.04200149] Bias: -0.7694448097885129\n",
            "Round: 310 Weight: [1.98197145 1.04290024] Bias: -0.7700508336040489\n",
            "Round: 311 Weight: [1.98372862 1.04379532] Bias: -0.7706538090626416\n",
            "Round: 312 Weight: [1.98547822 1.04468674] Bias: -0.7712537587315965\n",
            "Round: 313 Weight: [1.9872203  1.04557453] Bias: -0.7718507049463149\n",
            "Round: 314 Weight: [1.98895491 1.04645871] Bias: -0.7724446698133146\n",
            "Round: 315 Weight: [1.99068209 1.04733929] Bias: -0.7730356752132043\n",
            "Round: 316 Weight: [1.99240189 1.0482163 ] Bias: -0.7736237428036111\n",
            "Round: 317 Weight: [1.99411435 1.04908977] Bias: -0.7742088940220634\n",
            "Round: 318 Weight: [1.99581951 1.0499597 ] Bias: -0.774791150088828\n",
            "Round: 319 Weight: [1.99751741 1.05082612] Bias: -0.7753705320097051\n",
            "Round: 320 Weight: [1.99920811 1.05168905] Bias: -0.7759470605787784\n",
            "Round: 321 Weight: [2.00089165 1.05254851] Bias: -0.7765207563811245\n",
            "Round: 322 Weight: [2.00256806 1.05340452] Bias: -0.7770916397954803\n",
            "Round: 323 Weight: [2.00423739 1.0542571 ] Bias: -0.7776597309968695\n",
            "Round: 324 Weight: [2.00589968 1.05510626] Bias: -0.7782250499591887\n",
            "Round: 325 Weight: [2.00755497 1.05595203] Bias: -0.7787876164577556\n",
            "Round: 326 Weight: [2.0092033  1.05679442] Bias: -0.7793474500718169\n",
            "Round: 327 Weight: [2.01084472 1.05763346] Bias: -0.7799045701870195\n",
            "Round: 328 Weight: [2.01247927 1.05846917] Bias: -0.7804589959978436\n",
            "Round: 329 Weight: [2.01410698 1.05930155] Bias: -0.7810107465099997\n",
            "Round: 330 Weight: [2.0157279  1.06013063] Bias: -0.7815598405427895\n",
            "Round: 331 Weight: [2.01734206 1.06095643] Bias: -0.7821062967314312\n",
            "Round: 332 Weight: [2.0189495  1.06177897] Bias: -0.7826501335293505\n",
            "Round: 333 Weight: [2.02055027 1.06259825] Bias: -0.7831913692104371\n",
            "Round: 334 Weight: [2.02214439 1.06341431] Bias: -0.7837300218712675\n",
            "Round: 335 Weight: [2.02373192 1.06422716] Bias: -0.7842661094332956\n",
            "Round: 336 Weight: [2.02531289 1.06503682] Bias: -0.7847996496450097\n",
            "Round: 337 Weight: [2.02688733 1.0658433 ] Bias: -0.785330660084059\n",
            "Round: 338 Weight: [2.02845528 1.06664662] Bias: -0.7858591581593478\n",
            "Round: 339 Weight: [2.03001678 1.06744679] Bias: -0.7863851611130993\n",
            "Round: 340 Weight: [2.03157186 1.06824384] Bias: -0.786908686022889\n",
            "Round: 341 Weight: [2.03312057 1.06903779] Bias: -0.7874297498036487\n",
            "Round: 342 Weight: [2.03466294 1.06982864] Bias: -0.7879483692096407\n",
            "Round: 343 Weight: [2.036199   1.07061641] Bias: -0.7884645608364044\n",
            "Round: 344 Weight: [2.0377288  1.07140113] Bias: -0.7889783411226726\n",
            "Round: 345 Weight: [2.03925236 1.0721828 ] Bias: -0.7894897263522628\n",
            "Round: 346 Weight: [2.04076971 1.07296145] Bias: -0.7899987326559383\n",
            "Round: 347 Weight: [2.04228091 1.07373709] Bias: -0.7905053760132449\n",
            "Round: 348 Weight: [2.04378597 1.07450973] Bias: -0.7910096722543194\n",
            "Round: 349 Weight: [2.04528494 1.07527939] Bias: -0.7915116370616735\n",
            "Round: 350 Weight: [2.04677784 1.07604609] Bias: -0.7920112859719511\n",
            "Round: 351 Weight: [2.04826472 1.07680984] Bias: -0.7925086343776612\n",
            "Round: 352 Weight: [2.0497456  1.07757066] Bias: -0.7930036975288857\n",
            "Round: 353 Weight: [2.05122051 1.07832857] Bias: -0.7934964905349632\n",
            "Round: 354 Weight: [2.0526895  1.07908357] Bias: -0.7939870283661489\n",
            "Round: 355 Weight: [2.05415259 1.07983568] Bias: -0.7944753258552506\n",
            "Round: 356 Weight: [2.05560982 1.08058492] Bias: -0.7949613976992422\n",
            "Round: 357 Weight: [2.05706122 1.0813313 ] Bias: -0.7954452584608543\n",
            "Round: 358 Weight: [2.05850681 1.08207485] Bias: -0.7959269225701419\n",
            "Round: 359 Weight: [2.05994664 1.08281556] Bias: -0.7964064043260306\n",
            "Round: 360 Weight: [2.06138073 1.08355346] Bias: -0.7968837178978417\n",
            "Round: 361 Weight: [2.06280911 1.08428856] Bias: -0.797358877326795\n",
            "Round: 362 Weight: [2.06423182 1.08502088] Bias: -0.797831896527491\n",
            "Round: 363 Weight: [2.06564889 1.08575043] Bias: -0.7983027892893727\n",
            "Round: 364 Weight: [2.06706034 1.08647722] Bias: -0.7987715692781672\n",
            "Round: 365 Weight: [2.0684662  1.08720127] Bias: -0.799238250037307\n",
            "Round: 366 Weight: [2.06986652 1.08792259] Bias: -0.7997028449893321\n",
            "Round: 367 Weight: [2.0712613  1.08864119] Bias: -0.8001653674372723\n",
            "Round: 368 Weight: [2.0726506 1.0893571] Bias: -0.8006258305660109\n",
            "Round: 369 Weight: [2.07403443 1.09007031] Bias: -0.8010842474436295\n",
            "Round: 370 Weight: [2.07541282 1.09078086] Bias: -0.8015406310227348\n",
            "Round: 371 Weight: [2.07678581 1.09148874] Bias: -0.8019949941417664\n",
            "Round: 372 Weight: [2.07815342 1.09219398] Bias: -0.8024473495262879\n",
            "Round: 373 Weight: [2.07951567 1.09289658] Bias: -0.8028977097902597\n",
            "Round: 374 Weight: [2.08087261 1.09359656] Bias: -0.8033460874372943\n",
            "Round: 375 Weight: [2.08222425 1.09429393] Bias: -0.8037924948618961\n",
            "Round: 376 Weight: [2.08357063 1.09498871] Bias: -0.8042369443506824\n",
            "Round: 377 Weight: [2.08491177 1.0956809 ] Bias: -0.8046794480835896\n",
            "Round: 378 Weight: [2.0862477  1.09637053] Bias: -0.8051200181350622\n",
            "Round: 379 Weight: [2.08757845 1.0970576 ] Bias: -0.8055586664752264\n",
            "Round: 380 Weight: [2.08890404 1.09774213] Bias: -0.805995404971048\n",
            "Round: 381 Weight: [2.0902245  1.09842412] Bias: -0.8064302453874743\n",
            "Round: 382 Weight: [2.09153985 1.0991036 ] Bias: -0.8068631993885611\n",
            "Round: 383 Weight: [2.09285014 1.09978056] Bias: -0.807294278538585\n",
            "Round: 384 Weight: [2.09415537 1.10045504] Bias: -0.8077234943031407\n",
            "Round: 385 Weight: [2.09545557 1.10112703] Bias: -0.8081508580502236\n",
            "Round: 386 Weight: [2.09675078 1.10179655] Bias: -0.8085763810512981\n",
            "Round: 387 Weight: [2.09804102 1.10246361] Bias: -0.8090000744823526\n",
            "Round: 388 Weight: [2.09932631 1.10312822] Bias: -0.8094219494249391\n",
            "Round: 389 Weight: [2.10060668 1.1037904 ] Bias: -0.8098420168672007\n",
            "Round: 390 Weight: [2.10188216 1.10445016] Bias: -0.810260287704885\n",
            "Round: 391 Weight: [2.10315276 1.10510751] Bias: -0.8106767727423437\n",
            "Round: 392 Weight: [2.10441851 1.10576245] Bias: -0.8110914826935204\n",
            "Round: 393 Weight: [2.10567945 1.10641501] Bias: -0.811504428182924\n",
            "Round: 394 Weight: [2.10693559 1.10706519] Bias: -0.8119156197465913\n",
            "Round: 395 Weight: [2.10818695 1.107713  ] Bias: -0.8123250678330353\n",
            "Round: 396 Weight: [2.10943357 1.10835846] Bias: -0.8127327828041825\n",
            "Round: 397 Weight: [2.11067546 1.10900158] Bias: -0.8131387749362974\n",
            "Round: 398 Weight: [2.11191265 1.10964237] Bias: -0.8135430544208957\n",
            "Round: 399 Weight: [2.11314516 1.11028083] Bias: -0.813945631365645\n",
            "Round: 400 Weight: [2.11437302 1.11091698] Bias: -0.8143465157952549\n",
            "Round: 401 Weight: [2.11559625 1.11155084] Bias: -0.8147457176523543\n",
            "Round: 402 Weight: [2.11681487 1.1121824 ] Bias: -0.8151432467983594\n",
            "Round: 403 Weight: [2.11802891 1.11281169] Bias: -0.815539113014329\n",
            "Round: 404 Weight: [2.11923838 1.11343871] Bias: -0.8159333260018096\n",
            "Round: 405 Weight: [2.12044332 1.11406348] Bias: -0.8163258953836697\n",
            "Round: 406 Weight: [2.12164374 1.114686  ] Bias: -0.8167168307049237\n",
            "Round: 407 Weight: [2.12283967 1.11530628] Bias: -0.8171061414335451\n",
            "Round: 408 Weight: [2.12403112 1.11592434] Bias: -0.8174938369612693\n",
            "Round: 409 Weight: [2.12521813 1.11654019] Bias: -0.8178799266043871\n",
            "Round: 410 Weight: [2.1264007  1.11715383] Bias: -0.8182644196045273\n",
            "Round: 411 Weight: [2.12757888 1.11776527] Bias: -0.81864732512943\n",
            "Round: 412 Weight: [2.12875266 1.11837453] Bias: -0.8190286522737097\n",
            "Round: 413 Weight: [2.12992209 1.11898162] Bias: -0.8194084100596101\n",
            "Round: 414 Weight: [2.13108717 1.11958655] Bias: -0.8197866074377479\n",
            "Round: 415 Weight: [2.13224793 1.12018932] Bias: -0.8201632532878483\n",
            "Round: 416 Weight: [2.1334044  1.12078994] Bias: -0.8205383564194716\n",
            "Round: 417 Weight: [2.13455658 1.12138844] Bias: -0.8209119255727297\n",
            "Round: 418 Weight: [2.13570451 1.1219848 ] Bias: -0.821283969418995\n",
            "Round: 419 Weight: [2.1368482  1.12257906] Bias: -0.8216544965615995\n",
            "Round: 420 Weight: [2.13798767 1.12317121] Bias: -0.8220235155365263\n",
            "Round: 421 Weight: [2.13912295 1.12376126] Bias: -0.8223910348130917\n",
            "Round: 422 Weight: [2.14025405 1.12434922] Bias: -0.8227570627946194\n",
            "Round: 423 Weight: [2.141381   1.12493511] Bias: -0.8231216078191064\n",
            "Round: 424 Weight: [2.14250381 1.12551894] Bias: -0.8234846781598807\n",
            "Round: 425 Weight: [2.14362251 1.1261007 ] Bias: -0.8238462820262512\n",
            "Round: 426 Weight: [2.1447371  1.12668042] Bias: -0.8242064275641492\n",
            "Round: 427 Weight: [2.14584763 1.1272581 ] Bias: -0.8245651228567626\n",
            "Round: 428 Weight: [2.14695409 1.12783374] Bias: -0.8249223759251625\n",
            "Round: 429 Weight: [2.14805652 1.12840737] Bias: -0.8252781947289212\n",
            "Round: 430 Weight: [2.14915493 1.12897898] Bias: -0.8256325871667244\n",
            "Round: 431 Weight: [2.15024933 1.12954859] Bias: -0.8259855610769746\n",
            "Round: 432 Weight: [2.15133976 1.13011621] Bias: -0.826337124238388\n",
            "Round: 433 Weight: [2.15242623 1.13068184] Bias: -0.8266872843705838\n",
            "Round: 434 Weight: [2.15350875 1.1312455 ] Bias: -0.827036049134667\n",
            "Round: 435 Weight: [2.15458735 1.13180719] Bias: -0.8273834261338037\n",
            "Round: 436 Weight: [2.15566204 1.13236692] Bias: -0.8277294229137897\n",
            "Round: 437 Weight: [2.15673285 1.1329247 ] Bias: -0.8280740469636125\n",
            "Round: 438 Weight: [2.15779978 1.13348053] Bias: -0.8284173057160065\n",
            "Round: 439 Weight: [2.15886286 1.13403444] Bias: -0.8287592065480013\n",
            "Round: 440 Weight: [2.15992212 1.13458642] Bias: -0.8290997567814645\n",
            "Round: 441 Weight: [2.16097755 1.13513648] Bias: -0.8294389636836369\n",
            "Round: 442 Weight: [2.16202919 1.13568464] Bias: -0.8297768344676619\n",
            "Round: 443 Weight: [2.16307704 1.1362309 ] Bias: -0.830113376293109\n",
            "Round: 444 Weight: [2.16412114 1.13677527] Bias: -0.8304485962664905\n",
            "Round: 445 Weight: [2.16516149 1.13731775] Bias: -0.8307825014417729\n",
            "Round: 446 Weight: [2.16619811 1.13785836] Bias: -0.8311150988208815\n",
            "Round: 447 Weight: [2.16723102 1.13839711] Bias: -0.8314463953541997\n",
            "Round: 448 Weight: [2.16826024 1.13893399] Bias: -0.8317763979410624\n",
            "Round: 449 Weight: [2.16928578 1.13946903] Bias: -0.8321051134302433\n",
            "Round: 450 Weight: [2.17030766 1.14000222] Bias: -0.832432548620437\n",
            "Round: 451 Weight: [2.1713259  1.14053358] Bias: -0.8327587102607353\n",
            "Round: 452 Weight: [2.17234051 1.14106312] Bias: -0.8330836050510981\n",
            "Round: 453 Weight: [2.17335152 1.14159083] Bias: -0.8334072396428185\n",
            "Round: 454 Weight: [2.17435893 1.14211674] Bias: -0.8337296206389831\n",
            "Round: 455 Weight: [2.17536276 1.14264084] Bias: -0.8340507545949267\n",
            "Round: 456 Weight: [2.17636304 1.14316315] Bias: -0.8343706480186817\n",
            "Round: 457 Weight: [2.17735977 1.14368368] Bias: -0.8346893073714224\n",
            "Round: 458 Weight: [2.17835297 1.14420242] Bias: -0.8350067390679048\n",
            "Round: 459 Weight: [2.17934266 1.14471939] Bias: -0.8353229494769001\n",
            "Round: 460 Weight: [2.18032885 1.1452346 ] Bias: -0.8356379449216249\n",
            "Round: 461 Weight: [2.18131156 1.14574805] Bias: -0.8359517316801649\n",
            "Round: 462 Weight: [2.18229081 1.14625975] Bias: -0.8362643159858949\n",
            "Round: 463 Weight: [2.18326661 1.14676971] Bias: -0.8365757040278937\n",
            "Round: 464 Weight: [2.18423898 1.14727793] Bias: -0.8368859019513545\n",
            "Round: 465 Weight: [2.18520793 1.14778443] Bias: -0.8371949158579898\n",
            "Round: 466 Weight: [2.18617347 1.14828921] Bias: -0.8375027518064332\n",
            "Round: 467 Weight: [2.18713563 1.14879227] Bias: -0.8378094158126355\n",
            "Round: 468 Weight: [2.18809442 1.14929364] Bias: -0.8381149138502567\n",
            "Round: 469 Weight: [2.18904984 1.1497933 ] Bias: -0.8384192518510541\n",
            "Round: 470 Weight: [2.19000193 1.15029127] Bias: -0.8387224357052652\n",
            "Round: 471 Weight: [2.19095069 1.15078756] Bias: -0.8390244712619866\n",
            "Round: 472 Weight: [2.19189613 1.15128217] Bias: -0.8393253643295496\n",
            "Round: 473 Weight: [2.19283828 1.15177512] Bias: -0.8396251206758903\n",
            "Round: 474 Weight: [2.19377715 1.1522664 ] Bias: -0.8399237460289164\n",
            "Round: 475 Weight: [2.19471274 1.15275602] Bias: -0.8402212460768693\n",
            "Round: 476 Weight: [2.19564508 1.153244  ] Bias: -0.8405176264686833\n",
            "Round: 477 Weight: [2.19657418 1.15373033] Bias: -0.8408128928143397\n",
            "Round: 478 Weight: [2.19750006 1.15421503] Bias: -0.8411070506852174\n",
            "Round: 479 Weight: [2.19842272 1.1546981 ] Bias: -0.8414001056144399\n",
            "Round: 480 Weight: [2.19934219 1.15517955] Bias: -0.8416920630972183\n",
            "Round: 481 Weight: [2.20025847 1.15565939] Bias: -0.8419829285911905\n",
            "Round: 482 Weight: [2.20117158 1.15613762] Bias: -0.8422727075167565\n",
            "Round: 483 Weight: [2.20208153 1.15661424] Bias: -0.8425614052574109\n",
            "Round: 484 Weight: [2.20298835 1.15708927] Bias: -0.84284902716007\n",
            "Round: 485 Weight: [2.20389203 1.15756272] Bias: -0.8431355785353981\n",
            "Round: 486 Weight: [2.20479261 1.15803458] Bias: -0.8434210646581272\n",
            "Round: 487 Weight: [2.20569008 1.15850487] Bias: -0.8437054907673754\n",
            "Round: 488 Weight: [2.20658446 1.15897358] Bias: -0.8439888620669613\n",
            "Round: 489 Weight: [2.20747577 1.15944074] Bias: -0.8442711837257144\n",
            "Round: 490 Weight: [2.20836401 1.15990634] Bias: -0.8445524608777829\n",
            "Round: 491 Weight: [2.20924921 1.16037039] Bias: -0.8448326986229377\n",
            "Round: 492 Weight: [2.21013137 1.1608329 ] Bias: -0.8451119020268739\n",
            "Round: 493 Weight: [2.21101052 1.16129387] Bias: -0.8453900761215078\n",
            "Round: 494 Weight: [2.21188665 1.16175331] Bias: -0.845667225905272\n",
            "Round: 495 Weight: [2.21275979 1.16221123] Bias: -0.8459433563434063\n",
            "Round: 496 Weight: [2.21362994 1.16266763] Bias: -0.8462184723682467\n",
            "Round: 497 Weight: [2.21449713 1.16312252] Bias: -0.8464925788795098\n",
            "Round: 498 Weight: [2.21536136 1.1635759 ] Bias: -0.8467656807445758\n",
            "Round: 499 Weight: [2.21622264 1.16402778] Bias: -0.8470377827987673\n",
            "Round: 500 Weight: [2.21708099 1.16447817] Bias: -0.8473088898456254\n",
            "Round: 501 Weight: [2.21793642 1.16492707] Bias: -0.8475790066571834\n",
            "Round: 502 Weight: [2.21878894 1.16537449] Bias: -0.8478481379742372\n",
            "Round: 503 Weight: [2.21963857 1.16582044] Bias: -0.8481162885066127\n",
            "Round: 504 Weight: [2.22048532 1.16626491] Bias: -0.8483834629334309\n",
            "Round: 505 Weight: [2.22132919 1.16670792] Bias: -0.8486496659033699\n",
            "Round: 506 Weight: [2.22217021 1.16714947] Bias: -0.8489149020349238\n",
            "Round: 507 Weight: [2.22300838 1.16758958] Bias: -0.8491791759166599\n",
            "Round: 508 Weight: [2.22384371 1.16802823] Bias: -0.8494424921074722\n",
            "Round: 509 Weight: [2.22467623 1.16846545] Bias: -0.8497048551368328\n",
            "Round: 510 Weight: [2.22550593 1.16890123] Bias: -0.8499662695050405\n",
            "Round: 511 Weight: [2.22633283 1.16933558] Bias: -0.850226739683467\n",
            "Round: 512 Weight: [2.22715695 1.16976851] Bias: -0.8504862701148003\n",
            "Round: 513 Weight: [2.22797829 1.17020002] Bias: -0.8507448652132859\n",
            "Round: 514 Weight: [2.22879687 1.17063012] Bias: -0.8510025293649651\n",
            "Round: 515 Weight: [2.2296127  1.17105881] Bias: -0.8512592669279113\n",
            "Round: 516 Weight: [2.23042579 1.1714861 ] Bias: -0.8515150822324636\n",
            "Round: 517 Weight: [2.23123614 1.171912  ] Bias: -0.851769979581458\n",
            "Round: 518 Weight: [2.23204378 1.17233651] Bias: -0.852023963250456\n",
            "Round: 519 Weight: [2.23284871 1.17275963] Bias: -0.852277037487972\n",
            "Round: 520 Weight: [2.23365095 1.17318138] Bias: -0.8525292065156965\n",
            "Round: 521 Weight: [2.2344505  1.17360175] Bias: -0.8527804745287189\n",
            "Round: 522 Weight: [2.23524738 1.17402075] Bias: -0.8530308456957465\n",
            "Round: 523 Weight: [2.2360416 1.1744384] Bias: -0.8532803241593226\n",
            "Round: 524 Weight: [2.23683317 1.17485468] Bias: -0.8535289140360415\n",
            "Round: 525 Weight: [2.23762209 1.17526961] Bias: -0.8537766194167612\n",
            "Round: 526 Weight: [2.23840839 1.1756832 ] Bias: -0.8540234443668149\n",
            "Round: 527 Weight: [2.23919207 1.17609545] Bias: -0.8542693929262196\n",
            "Round: 528 Weight: [2.23997314 1.17650636] Bias: -0.8545144691098828\n",
            "Round: 529 Weight: [2.24075162 1.17691594] Bias: -0.854758676907807\n",
            "Round: 530 Weight: [2.24152751 1.17732419] Bias: -0.8550020202852926\n",
            "Round: 531 Weight: [2.24230082 1.17773112] Bias: -0.8552445031831379\n",
            "Round: 532 Weight: [2.24307157 1.17813674] Bias: -0.8554861295178383\n",
            "Round: 533 Weight: [2.24383976 1.17854105] Bias: -0.8557269031817825\n",
            "Round: 534 Weight: [2.24460541 1.17894406] Bias: -0.855966828043447\n",
            "Round: 535 Weight: [2.24536852 1.17934576] Bias: -0.8562059079475892\n",
            "Round: 536 Weight: [2.24612911 1.17974617] Bias: -0.8564441467154377\n",
            "Round: 537 Weight: [2.24688719 1.18014529] Bias: -0.8566815481448813\n",
            "Round: 538 Weight: [2.24764276 1.18054312] Bias: -0.8569181160106562\n",
            "Round: 539 Weight: [2.24839584 1.18093968] Bias: -0.8571538540645309\n",
            "Round: 540 Weight: [2.24914644 1.18133496] Bias: -0.85738876603549\n",
            "Round: 541 Weight: [2.24989457 1.18172897] Bias: -0.8576228556299148\n",
            "Round: 542 Weight: [2.25064023 1.18212171] Bias: -0.8578561265317641\n",
            "Round: 543 Weight: [2.25138344 1.1825132 ] Bias: -0.8580885824027515\n",
            "Round: 544 Weight: [2.2521242  1.18290342] Bias: -0.858320226882522\n",
            "Round: 545 Weight: [2.25286254 1.1832924 ] Bias: -0.858551063588826\n",
            "Round: 546 Weight: [2.25359845 1.18368014] Bias: -0.858781096117693\n",
            "Round: 547 Weight: [2.25433194 1.18406663] Bias: -0.8590103280436019\n",
            "Round: 548 Weight: [2.25506303 1.18445188] Bias: -0.8592387629196508\n",
            "Round: 549 Weight: [2.25579173 1.18483591] Bias: -0.8594664042777249\n",
            "Round: 550 Weight: [2.25651804 1.1852187 ] Bias: -0.8596932556286625\n",
            "Round: 551 Weight: [2.25724198 1.18560028] Bias: -0.8599193204624198\n",
            "Round: 552 Weight: [2.25796355 1.18598064] Bias: -0.8601446022482339\n",
            "Round: 553 Weight: [2.25868276 1.18635978] Bias: -0.8603691044347839\n",
            "Round: 554 Weight: [2.25939963 1.18673772] Bias: -0.8605928304503511\n",
            "Round: 555 Weight: [2.26011415 1.18711445] Bias: -0.8608157837029774\n",
            "Round: 556 Weight: [2.26082635 1.18748999] Bias: -0.8610379675806218\n",
            "Round: 557 Weight: [2.26153623 1.18786432] Bias: -0.8612593854513161\n",
            "Round: 558 Weight: [2.26224381 1.18823747] Bias: -0.8614800406633183\n",
            "Round: 559 Weight: [2.26294907 1.18860944] Bias: -0.8616999365452654\n",
            "Round: 560 Weight: [2.26365205 1.18898022] Bias: -0.8619190764063243\n",
            "Round: 561 Weight: [2.26435275 1.18934983] Bias: -0.8621374635363407\n",
            "Round: 562 Weight: [2.26505117 1.18971826] Bias: -0.8623551012059879\n",
            "Round: 563 Weight: [2.26574732 1.19008553] Bias: -0.8625719926669131\n",
            "Round: 564 Weight: [2.26644122 1.19045163] Bias: -0.8627881411518826\n",
            "Round: 565 Weight: [2.26713287 1.19081657] Bias: -0.863003549874926\n",
            "Round: 566 Weight: [2.26782229 1.19118036] Bias: -0.8632182220314785\n",
            "Round: 567 Weight: [2.26850947 1.191543  ] Bias: -0.8634321607985221\n",
            "Round: 568 Weight: [2.26919443 1.1919045 ] Bias: -0.8636453693347259\n",
            "Round: 569 Weight: [2.26987718 1.19226485] Bias: -0.8638578507805839\n",
            "Round: 570 Weight: [2.27055773 1.19262406] Bias: -0.8640696082585528\n",
            "Round: 571 Weight: [2.27123608 1.19298214] Bias: -0.8642806448731882\n",
            "Round: 572 Weight: [2.27191225 1.19333909] Bias: -0.8644909637112786\n",
            "Round: 573 Weight: [2.27258624 1.19369492] Bias: -0.8647005678419795\n",
            "Round: 574 Weight: [2.27325806 1.19404963] Bias: -0.8649094603169452\n",
            "Round: 575 Weight: [2.27392771 1.19440322] Bias: -0.86511764417046\n",
            "Round: 576 Weight: [2.27459522 1.1947557 ] Bias: -0.865325122419568\n",
            "Round: 577 Weight: [2.27526058 1.19510707] Bias: -0.8655318980642017\n",
            "Round: 578 Weight: [2.2759238  1.19545733] Bias: -0.8657379740873091\n",
            "Round: 579 Weight: [2.2765849 1.1958065] Bias: -0.8659433534549802\n",
            "Round: 580 Weight: [2.27724388 1.19615457] Bias: -0.8661480391165719\n",
            "Round: 581 Weight: [2.27790074 1.19650155] Bias: -0.8663520340048321\n",
            "Round: 582 Weight: [2.2785555  1.19684744] Bias: -0.8665553410360222\n",
            "Round: 583 Weight: [2.27920817 1.19719225] Bias: -0.8667579631100388\n",
            "Round: 584 Weight: [2.27985875 1.19753598] Bias: -0.8669599031105346\n",
            "Round: 585 Weight: [2.28050725 1.19787863] Bias: -0.8671611639050371\n",
            "Round: 586 Weight: [2.28115368 1.19822021] Bias: -0.8673617483450673\n",
            "Round: 587 Weight: [2.28179805 1.19856072] Bias: -0.8675616592662574\n",
            "Round: 588 Weight: [2.28244036 1.19890017] Bias: -0.8677608994884662\n",
            "Round: 589 Weight: [2.28308062 1.19923856] Bias: -0.867959471815895\n",
            "Round: 590 Weight: [2.28371884 1.19957589] Bias: -0.8681573790372007\n",
            "Round: 591 Weight: [2.28435504 1.19991217] Bias: -0.86835462392561\n",
            "Round: 592 Weight: [2.2849892 1.2002474] Bias: -0.8685512092390307\n",
            "Round: 593 Weight: [2.28562136 1.20058159] Bias: -0.8687471377201629\n",
            "Round: 594 Weight: [2.2862515  1.20091474] Bias: -0.868942412096609\n",
            "Round: 595 Weight: [2.28687964 1.20124685] Bias: -0.8691370350809831\n",
            "Round: 596 Weight: [2.28750579 1.20157792] Bias: -0.8693310093710184\n",
            "Round: 597 Weight: [2.28812995 1.20190797] Bias: -0.8695243376496747\n",
            "Round: 598 Weight: [2.28875213 1.20223699] Bias: -0.8697170225852449\n",
            "Round: 599 Weight: [2.28937235 1.20256499] Bias: -0.8699090668314593\n",
            "Round: 600 Weight: [2.2899906  1.20289197] Bias: -0.8701004730275905\n",
            "Round: 601 Weight: [2.29060689 1.20321794] Bias: -0.8702912437985567\n",
            "Round: 602 Weight: [2.29122123 1.2035429 ] Bias: -0.8704813817550238\n",
            "Round: 603 Weight: [2.29183364 1.20386685] Bias: -0.8706708894935069\n",
            "Round: 604 Weight: [2.29244411 1.20418979] Bias: -0.8708597695964715\n",
            "Round: 605 Weight: [2.29305265 1.20451174] Bias: -0.8710480246324324\n",
            "Round: 606 Weight: [2.29365927 1.20483269] Bias: -0.8712356571560531\n",
            "Round: 607 Weight: [2.29426398 1.20515264] Bias: -0.8714226697082434\n",
            "Round: 608 Weight: [2.29486678 1.20547161] Bias: -0.871609064816257\n",
            "Round: 609 Weight: [2.29546769 1.20578959] Bias: -0.8717948449937869\n",
            "Round: 610 Weight: [2.29606671 1.20610659] Bias: -0.8719800127410616\n",
            "Round: 611 Weight: [2.29666384 1.20642262] Bias: -0.8721645705449393\n",
            "Round: 612 Weight: [2.29725909 1.20673766] Bias: -0.8723485208790018\n",
            "Round: 613 Weight: [2.29785248 1.20705174] Bias: -0.8725318662036472\n",
            "Round: 614 Weight: [2.298444   1.20736485] Bias: -0.8727146089661821\n",
            "Round: 615 Weight: [2.29903367 1.20767699] Bias: -0.8728967516009132\n",
            "Round: 616 Weight: [2.29962148 1.20798817] Bias: -0.8730782965292372\n",
            "Round: 617 Weight: [2.30020746 1.2082984 ] Bias: -0.8732592461597312\n",
            "Round: 618 Weight: [2.3007916  1.20860767] Bias: -0.8734396028882411\n",
            "Round: 619 Weight: [2.30137391 1.20891599] Bias: -0.8736193690979702\n",
            "Round: 620 Weight: [2.3019544  1.20922336] Bias: -0.8737985471595664\n",
            "Round: 621 Weight: [2.30253307 1.20952979] Bias: -0.8739771394312089\n",
            "Round: 622 Weight: [2.30310994 1.20983528] Bias: -0.8741551482586941\n",
            "Round: 623 Weight: [2.303685   1.21013983] Bias: -0.874332575975521\n",
            "Round: 624 Weight: [2.30425827 1.21044344] Bias: -0.8745094249029755\n",
            "Round: 625 Weight: [2.30482975 1.21074613] Bias: -0.8746856973502137\n",
            "Round: 626 Weight: [2.30539945 1.21104789] Bias: -0.874861395614346\n",
            "Round: 627 Weight: [2.30596737 1.21134872] Bias: -0.8750365219805182\n",
            "Round: 628 Weight: [2.30653353 1.21164864] Bias: -0.875211078721994\n",
            "Round: 629 Weight: [2.30709792 1.21194764] Bias: -0.8753850681002355\n",
            "Round: 630 Weight: [2.30766055 1.21224572] Bias: -0.8755584923649835\n",
            "Round: 631 Weight: [2.30822144 1.21254289] Bias: -0.875731353754337\n",
            "Round: 632 Weight: [2.30878058 1.21283915] Bias: -0.8759036544948321\n",
            "Round: 633 Weight: [2.30933799 1.21313451] Bias: -0.8760753968015204\n",
            "Round: 634 Weight: [2.30989367 1.21342897] Bias: -0.8762465828780461\n",
            "Round: 635 Weight: [2.31044762 1.21372253] Bias: -0.8764172149167236\n",
            "Round: 636 Weight: [2.31099986 1.2140152 ] Bias: -0.876587295098613\n",
            "Round: 637 Weight: [2.31155038 1.21430697] Bias: -0.876756825593596\n",
            "Round: 638 Weight: [2.3120992  1.21459785] Bias: -0.876925808560451\n",
            "Round: 639 Weight: [2.31264632 1.21488785] Bias: -0.8770942461469273\n",
            "Round: 640 Weight: [2.31319174 1.21517697] Bias: -0.877262140489819\n",
            "Round: 641 Weight: [2.31373548 1.2154652 ] Bias: -0.8774294937150378\n",
            "Round: 642 Weight: [2.31427754 1.21575257] Bias: -0.8775963079376856\n",
            "Round: 643 Weight: [2.31481793 1.21603905] Bias: -0.8777625852621268\n",
            "Round: 644 Weight: [2.31535665 1.21632467] Bias: -0.8779283277820589\n",
            "Round: 645 Weight: [2.3158937  1.21660942] Bias: -0.8780935375805837\n",
            "Round: 646 Weight: [2.3164291  1.21689331] Bias: -0.8782582167302774\n",
            "Round: 647 Weight: [2.31696284 1.21717633] Bias: -0.8784223672932597\n",
            "Round: 648 Weight: [2.31749495 1.2174585 ] Bias: -0.8785859913212636\n",
            "Round: 649 Weight: [2.31802541 1.21773981] Bias: -0.8787490908557027\n",
            "Round: 650 Weight: [2.31855424 1.21802027] Bias: -0.8789116679277401\n",
            "Round: 651 Weight: [2.31908145 1.21829988] Bias: -0.8790737245583549\n",
            "Round: 652 Weight: [2.31960703 1.21857864] Bias: -0.8792352627584092\n",
            "Round: 653 Weight: [2.320131   1.21885656] Bias: -0.8793962845287148\n",
            "Round: 654 Weight: [2.32065336 1.21913364] Bias: -0.8795567918600976\n",
            "Round: 655 Weight: [2.32117412 1.21940989] Bias: -0.8797167867334641\n",
            "Round: 656 Weight: [2.32169327 1.21968529] Bias: -0.8798762711198649\n",
            "Round: 657 Weight: [2.32221084 1.21995987] Bias: -0.8800352469805592\n",
            "Round: 658 Weight: [2.32272682 1.22023362] Bias: -0.8801937162670785\n",
            "Round: 659 Weight: [2.32324122 1.22050654] Bias: -0.8803516809212892\n",
            "Round: 660 Weight: [2.32375404 1.22077864] Bias: -0.8805091428754553\n",
            "Round: 661 Weight: [2.32426529 1.22104992] Bias: -0.8806661040523006\n",
            "Round: 662 Weight: [2.32477498 1.22132038] Bias: -0.8808225663650696\n",
            "Round: 663 Weight: [2.32528312 1.22159003] Bias: -0.8809785317175891\n",
            "Round: 664 Weight: [2.3257897  1.22185886] Bias: -0.8811340020043285\n",
            "Round: 665 Weight: [2.32629473 1.22212689] Bias: -0.8812889791104597\n",
            "Round: 666 Weight: [2.32679822 1.22239411] Bias: -0.8814434649119167\n",
            "Round: 667 Weight: [2.32730017 1.22266053] Bias: -0.8815974612754548\n",
            "Round: 668 Weight: [2.32780059 1.22292614] Bias: -0.881750970058709\n",
            "Round: 669 Weight: [2.32829949 1.22319096] Bias: -0.881903993110252\n",
            "Round: 670 Weight: [2.32879687 1.22345498] Bias: -0.8820565322696525\n",
            "Round: 671 Weight: [2.32929273 1.22371821] Bias: -0.8822085893675315\n",
            "Round: 672 Weight: [2.32978708 1.22398065] Bias: -0.8823601662256197\n",
            "Round: 673 Weight: [2.33027993 1.22424231] Bias: -0.8825112646568136\n",
            "Round: 674 Weight: [2.33077128 1.22450318] Bias: -0.8826618864652311\n",
            "Round: 675 Weight: [2.33126114 1.22476327] Bias: -0.8828120334462672\n",
            "Round: 676 Weight: [2.33174951 1.22502257] Bias: -0.882961707386649\n",
            "Round: 677 Weight: [2.33223639 1.22528111] Bias: -0.8831109100644899\n",
            "Round: 678 Weight: [2.3327218  1.22553887] Bias: -0.883259643249344\n",
            "Round: 679 Weight: [2.33320573 1.22579585] Bias: -0.8834079087022597\n",
            "Round: 680 Weight: [2.3336882  1.22605207] Bias: -0.8835557081758328\n",
            "Round: 681 Weight: [2.33416921 1.22630753] Bias: -0.8837030434142598\n",
            "Round: 682 Weight: [2.33464875 1.22656222] Bias: -0.8838499161533894\n",
            "Round: 683 Weight: [2.33512685 1.22681615] Bias: -0.8839963281207754\n",
            "Round: 684 Weight: [2.3356035  1.22706932] Bias: -0.8841422810357282\n",
            "Round: 685 Weight: [2.33607871 1.22732174] Bias: -0.8842877766093654\n",
            "Round: 686 Weight: [2.33655248 1.2275734 ] Bias: -0.8844328165446632\n",
            "Round: 687 Weight: [2.33702482 1.22782431] Bias: -0.8845774025365065\n",
            "Round: 688 Weight: [2.33749573 1.22807448] Bias: -0.8847215362717391\n",
            "Round: 689 Weight: [2.33796522 1.2283239 ] Bias: -0.8848652194292131\n",
            "Round: 690 Weight: [2.33843329 1.22857258] Bias: -0.8850084536798385\n",
            "Round: 691 Weight: [2.33889995 1.22882051] Bias: -0.8851512406866316\n",
            "Round: 692 Weight: [2.3393652  1.22906771] Bias: -0.8852935821047639\n",
            "Round: 693 Weight: [2.33982905 1.22931418] Bias: -0.8854354795816101\n",
            "Round: 694 Weight: [2.3402915  1.22955991] Bias: -0.8855769347567954\n",
            "Round: 695 Weight: [2.34075257 1.22980491] Bias: -0.8857179492622438\n",
            "Round: 696 Weight: [2.34121224 1.23004919] Bias: -0.885858524722224\n",
            "Round: 697 Weight: [2.34167053 1.23029273] Bias: -0.8859986627533971\n",
            "Round: 698 Weight: [2.34212744 1.23053556] Bias: -0.8861383649648622\n",
            "Round: 699 Weight: [2.34258298 1.23077766] Bias: -0.8862776329582026\n",
            "Round: 700 Weight: [2.34303715 1.23101905] Bias: -0.8864164683275314\n",
            "Round: 701 Weight: [2.34348995 1.23125972] Bias: -0.8865548726595366\n",
            "Round: 702 Weight: [2.3439414  1.23149968] Bias: -0.8866928475335261\n",
            "Round: 703 Weight: [2.34439149 1.23173892] Bias: -0.8868303945214722\n",
            "Round: 704 Weight: [2.34484023 1.23197746] Bias: -0.886967515188056\n",
            "Round: 705 Weight: [2.34528763 1.23221529] Bias: -0.8871042110907112\n",
            "Round: 706 Weight: [2.34573368 1.23245242] Bias: -0.8872404837796675\n",
            "Round: 707 Weight: [2.3461784  1.23268885] Bias: -0.8873763347979938\n",
            "Round: 708 Weight: [2.34662179 1.23292458] Bias: -0.8875117656816417\n",
            "Round: 709 Weight: [2.34706385 1.23315961] Bias: -0.8876467779594871\n",
            "Round: 710 Weight: [2.34750459 1.23339394] Bias: -0.8877813731533734\n",
            "Round: 711 Weight: [2.34794401 1.23362759] Bias: -0.8879155527781526\n",
            "Round: 712 Weight: [2.34838212 1.23386054] Bias: -0.8880493183417278\n",
            "Round: 713 Weight: [2.34881892 1.23409281] Bias: -0.8881826713450938\n",
            "Round: 714 Weight: [2.34925441 1.23432439] Bias: -0.8883156132823783\n",
            "Round: 715 Weight: [2.3496886  1.23455529] Bias: -0.8884481456408829\n",
            "Round: 716 Weight: [2.3501215  1.23478551] Bias: -0.8885802699011232\n",
            "Round: 717 Weight: [2.35055311 1.23501505] Bias: -0.8887119875368688\n",
            "Round: 718 Weight: [2.35098343 1.23524391] Bias: -0.8888433000151833\n",
            "Round: 719 Weight: [2.35141247 1.2354721 ] Bias: -0.888974208796464\n",
            "Round: 720 Weight: [2.35184023 1.23569962] Bias: -0.8891047153344809\n",
            "Round: 721 Weight: [2.35226671 1.23592647] Bias: -0.8892348210764152\n",
            "Round: 722 Weight: [2.35269193 1.23615265] Bias: -0.8893645274628986\n",
            "Round: 723 Weight: [2.35311588 1.23637816] Bias: -0.8894938359280515\n",
            "Round: 724 Weight: [2.35353857 1.23660302] Bias: -0.8896227478995209\n",
            "Round: 725 Weight: [2.35396001 1.23682721] Bias: -0.8897512647985181\n",
            "Round: 726 Weight: [2.35438019 1.23705074] Bias: -0.8898793880398566\n",
            "Round: 727 Weight: [2.35479913 1.23727362] Bias: -0.8900071190319888\n",
            "Round: 728 Weight: [2.35521682 1.23749584] Bias: -0.8901344591770436\n",
            "Round: 729 Weight: [2.35563327 1.23771741] Bias: -0.8902614098708624\n",
            "Round: 730 Weight: [2.35604848 1.23793833] Bias: -0.8903879725030364\n",
            "Round: 731 Weight: [2.35646247 1.23815861] Bias: -0.8905141484569417\n",
            "Round: 732 Weight: [2.35687522 1.23837824] Bias: -0.890639939109776\n",
            "Round: 733 Weight: [2.35728676 1.23859722] Bias: -0.890765345832594\n",
            "Round: 734 Weight: [2.35769707 1.23881556] Bias: -0.8908903699903429\n",
            "Round: 735 Weight: [2.35810617 1.23903327] Bias: -0.8910150129418969\n",
            "Round: 736 Weight: [2.35851406 1.23925033] Bias: -0.8911392760400931\n",
            "Round: 737 Weight: [2.35892074 1.23946676] Bias: -0.8912631606317652\n",
            "Round: 738 Weight: [2.35932622 1.23968256] Bias: -0.8913866680577786\n",
            "Round: 739 Weight: [2.35973051 1.23989773] Bias: -0.8915097996530638\n",
            "Round: 740 Weight: [2.36013359 1.24011227] Bias: -0.8916325567466508\n",
            "Round: 741 Weight: [2.36053549 1.24032618] Bias: -0.8917549406617025\n",
            "Round: 742 Weight: [2.3609362  1.24053947] Bias: -0.8918769527155482\n",
            "Round: 743 Weight: [2.36133573 1.24075213] Bias: -0.891998594219717\n",
            "Round: 744 Weight: [2.36173408 1.24096418] Bias: -0.8921198664799698\n",
            "Round: 745 Weight: [2.36213125 1.2411756 ] Bias: -0.8922407707963331\n",
            "Round: 746 Weight: [2.36252725 1.24138641] Bias: -0.8923613084631309\n",
            "Round: 747 Weight: [2.36292209 1.2415966 ] Bias: -0.8924814807690168\n",
            "Round: 748 Weight: [2.36331576 1.24180618] Bias: -0.8926012889970062\n",
            "Round: 749 Weight: [2.36370828 1.24201515] Bias: -0.8927207344245081\n",
            "Round: 750 Weight: [2.36409963 1.24222352] Bias: -0.8928398183233563\n",
            "Round: 751 Weight: [2.36448984 1.24243127] Bias: -0.8929585419598415\n",
            "Round: 752 Weight: [2.3648789  1.24263842] Bias: -0.8930769065947411\n",
            "Round: 753 Weight: [2.36526682 1.24284497] Bias: -0.8931949134833516\n",
            "Round: 754 Weight: [2.36565359 1.24305092] Bias: -0.8933125638755178\n",
            "Round: 755 Weight: [2.36603923 1.24325626] Bias: -0.8934298590156645\n",
            "Round: 756 Weight: [2.36642374 1.24346101] Bias: -0.8935468001428257\n",
            "Round: 757 Weight: [2.36680712 1.24366517] Bias: -0.8936633884906753\n",
            "Round: 758 Weight: [2.36718937 1.24386873] Bias: -0.8937796252875565\n",
            "Round: 759 Weight: [2.3675705  1.24407171] Bias: -0.8938955117565116\n",
            "Round: 760 Weight: [2.36795052 1.24427409] Bias: -0.8940110491153115\n",
            "Round: 761 Weight: [2.36832942 1.24447588] Bias: -0.8941262385764844\n",
            "Round: 762 Weight: [2.36870721 1.24467709] Bias: -0.8942410813473454\n",
            "Round: 763 Weight: [2.36908389 1.24487772] Bias: -0.8943555786300246\n",
            "Round: 764 Weight: [2.36945947 1.24507776] Bias: -0.8944697316214965\n",
            "Round: 765 Weight: [2.36983395 1.24527723] Bias: -0.8945835415136075\n",
            "Round: 766 Weight: [2.37020734 1.24547611] Bias: -0.8946970094931049\n",
            "Round: 767 Weight: [2.37057963 1.24567443] Bias: -0.8948101367416642\n",
            "Round: 768 Weight: [2.37095083 1.24587216] Bias: -0.8949229244359174\n",
            "Round: 769 Weight: [2.37132095 1.24606933] Bias: -0.8950353737474801\n",
            "Round: 770 Weight: [2.37168999 1.24626592] Bias: -0.8951474858429794\n",
            "Round: 771 Weight: [2.37205795 1.24646194] Bias: -0.8952592618840811\n",
            "Round: 772 Weight: [2.37242484 1.2466574 ] Bias: -0.8953707030275162\n",
            "Round: 773 Weight: [2.37279065 1.2468523 ] Bias: -0.8954818104251083\n",
            "Round: 774 Weight: [2.3731554  1.24704662] Bias: -0.8955925852238001\n",
            "Round: 775 Weight: [2.37351909 1.24724039] Bias: -0.89570302856568\n",
            "Round: 776 Weight: [2.37388171 1.2474336 ] Bias: -0.8958131415880078\n",
            "Round: 777 Weight: [2.37424328 1.24762625] Bias: -0.8959229254232418\n",
            "Round: 778 Weight: [2.37460379 1.24781835] Bias: -0.896032381199064\n",
            "Round: 779 Weight: [2.37496326 1.24800989] Bias: -0.8961415100384061\n",
            "Round: 780 Weight: [2.37532167 1.24820088] Bias: -0.8962503130594752\n",
            "Round: 781 Weight: [2.37567905 1.24839131] Bias: -0.8963587913757791\n",
            "Round: 782 Weight: [2.37603538 1.2485812 ] Bias: -0.8964669460961515\n",
            "Round: 783 Weight: [2.37639068 1.24877054] Bias: -0.8965747783247773\n",
            "Round: 784 Weight: [2.37674494 1.24895934] Bias: -0.8966822891612173\n",
            "Round: 785 Weight: [2.37709818 1.24914759] Bias: -0.8967894797004329\n",
            "Round: 786 Weight: [2.37745039 1.2493353 ] Bias: -0.8968963510328108\n",
            "Round: 787 Weight: [2.37780158 1.24952247] Bias: -0.8970029042441877\n",
            "Round: 788 Weight: [2.37815174 1.2497091 ] Bias: -0.8971091404158739\n",
            "Round: 789 Weight: [2.37850089 1.24989519] Bias: -0.8972150606246777\n",
            "Round: 790 Weight: [2.37884903 1.25008075] Bias: -0.8973206659429296\n",
            "Round: 791 Weight: [2.37919616 1.25026578] Bias: -0.8974259574385055\n",
            "Round: 792 Weight: [2.37954228 1.25045027] Bias: -0.8975309361748509\n",
            "Round: 793 Weight: [2.3798874  1.25063423] Bias: -0.8976356032110039\n",
            "Round: 794 Weight: [2.38023151 1.25081767] Bias: -0.8977399596016186\n",
            "Round: 795 Weight: [2.38057464 1.25100058] Bias: -0.8978440063969882\n",
            "Round: 796 Weight: [2.38091676 1.25118296] Bias: -0.8979477446430685\n",
            "Round: 797 Weight: [2.3812579  1.25136482] Bias: -0.8980511753814996\n",
            "Round: 798 Weight: [2.38159805 1.25154616] Bias: -0.8981542996496298\n",
            "Round: 799 Weight: [2.38193722 1.25172697] Bias: -0.8982571184805375\n",
            "Round: 800 Weight: [2.3822754  1.25190727] Bias: -0.8983596329030533\n",
            "Round: 801 Weight: [2.38261261 1.25208706] Bias: -0.8984618439417832\n",
            "Round: 802 Weight: [2.38294884 1.25226632] Bias: -0.8985637526171295\n",
            "Round: 803 Weight: [2.3832841  1.25244508] Bias: -0.8986653599453136\n",
            "Round: 804 Weight: [2.3836184  1.25262332] Bias: -0.8987666669383976\n",
            "Round: 805 Weight: [2.38395173 1.25280105] Bias: -0.8988676746043055\n",
            "Round: 806 Weight: [2.38428409 1.25297827] Bias: -0.8989683839468455\n",
            "Round: 807 Weight: [2.3846155  1.25315499] Bias: -0.8990687959657307\n",
            "Round: 808 Weight: [2.38494595 1.2533312 ] Bias: -0.8991689116566007\n",
            "Round: 809 Weight: [2.38527545 1.25350691] Bias: -0.8992687320110424\n",
            "Round: 810 Weight: [2.385604   1.25368211] Bias: -0.8993682580166112\n",
            "Round: 811 Weight: [2.3859316  1.25385681] Bias: -0.8994674906568518\n",
            "Round: 812 Weight: [2.38625826 1.25403102] Bias: -0.8995664309113187\n",
            "Round: 813 Weight: [2.38658398 1.25420472] Bias: -0.8996650797555971\n",
            "Round: 814 Weight: [2.38690876 1.25437793] Bias: -0.8997634381613226\n",
            "Round: 815 Weight: [2.3872326  1.25455065] Bias: -0.8998615070962026\n",
            "Round: 816 Weight: [2.38755552 1.25472287] Bias: -0.8999592875240352\n",
            "Round: 817 Weight: [2.3878775  1.25489461] Bias: -0.9000567804047303\n",
            "Round: 818 Weight: [2.38819856 1.25506585] Bias: -0.9001539866943287\n",
            "Round: 819 Weight: [2.3885187 1.2552366] Bias: -0.9002509073450224\n",
            "Round: 820 Weight: [2.38883792 1.25540687] Bias: -0.9003475433051741\n",
            "Round: 821 Weight: [2.38915622 1.25557665] Bias: -0.9004438955193362\n",
            "Round: 822 Weight: [2.3894736  1.25574595] Bias: -0.9005399649282712\n",
            "Round: 823 Weight: [2.38979008 1.25591476] Bias: -0.9006357524689699\n",
            "Round: 824 Weight: [2.39010564 1.25608309] Bias: -0.9007312590746713\n",
            "Round: 825 Weight: [2.3904203  1.25625095] Bias: -0.9008264856748814\n",
            "Round: 826 Weight: [2.39073406 1.25641833] Bias: -0.9009214331953919\n",
            "Round: 827 Weight: [2.39104692 1.25658523] Bias: -0.9010161025582989\n",
            "Round: 828 Weight: [2.39135888 1.25675165] Bias: -0.9011104946820222\n",
            "Round: 829 Weight: [2.39166995 1.25691761] Bias: -0.9012046104813232\n",
            "Round: 830 Weight: [2.39198013 1.25708309] Bias: -0.9012984508673234\n",
            "Round: 831 Weight: [2.39228941 1.2572481 ] Bias: -0.9013920167475231\n",
            "Round: 832 Weight: [2.39259782 1.25741264] Bias: -0.9014853090258191\n",
            "Round: 833 Weight: [2.39290534 1.25757672] Bias: -0.9015783286025232\n",
            "Round: 834 Weight: [2.39321198 1.25774032] Bias: -0.9016710763743796\n",
            "Round: 835 Weight: [2.39351774 1.25790347] Bias: -0.9017635532345835\n",
            "Round: 836 Weight: [2.39382263 1.25806615] Bias: -0.901855760072798\n",
            "Round: 837 Weight: [2.39412665 1.25822837] Bias: -0.9019476977751725\n",
            "Round: 838 Weight: [2.3944298  1.25839013] Bias: -0.9020393672243597\n",
            "Round: 839 Weight: [2.39473208 1.25855143] Bias: -0.9021307692995333\n",
            "Round: 840 Weight: [2.3950335  1.25871227] Bias: -0.9022219048764049\n",
            "Round: 841 Weight: [2.39533405 1.25887266] Bias: -0.9023127748272415\n",
            "Round: 842 Weight: [2.39563376 1.25903259] Bias: -0.9024033800208826\n",
            "Round: 843 Weight: [2.3959326  1.25919207] Bias: -0.9024937213227572\n",
            "Round: 844 Weight: [2.39623059 1.25935109] Bias: -0.9025837995949003\n",
            "Round: 845 Weight: [2.39652774 1.25950967] Bias: -0.90267361569597\n",
            "Round: 846 Weight: [2.39682403 1.2596678 ] Bias: -0.9027631704812641\n",
            "Round: 847 Weight: [2.39711948 1.25982548] Bias: -0.9028524648027365\n",
            "Round: 848 Weight: [2.39741409 1.25998271] Bias: -0.902941499509014\n",
            "Round: 849 Weight: [2.39770786 1.2601395 ] Bias: -0.9030302754454121\n",
            "Round: 850 Weight: [2.39800079 1.26029585] Bias: -0.9031187934539519\n",
            "Round: 851 Weight: [2.39829289 1.26045175] Bias: -0.9032070543733756\n",
            "Round: 852 Weight: [2.39858416 1.26060722] Bias: -0.903295059039163\n",
            "Round: 853 Weight: [2.3988746  1.26076224] Bias: -0.9033828082835472\n",
            "Round: 854 Weight: [2.39916421 1.26091682] Bias: -0.9034703029355309\n",
            "Round: 855 Weight: [2.399453   1.26107097] Bias: -0.9035575438209013\n",
            "Round: 856 Weight: [2.39974096 1.26122469] Bias: -0.9036445317622466\n",
            "Round: 857 Weight: [2.40002811 1.26137797] Bias: -0.9037312675789712\n",
            "Round: 858 Weight: [2.40031445 1.26153081] Bias: -0.903817752087311\n",
            "Round: 859 Weight: [2.40059996 1.26168323] Bias: -0.9039039861003493\n",
            "Round: 860 Weight: [2.40088467 1.26183522] Bias: -0.9039899704280314\n",
            "Round: 861 Weight: [2.40116857 1.26198677] Bias: -0.9040757058771803\n",
            "Round: 862 Weight: [2.40145167 1.2621379 ] Bias: -0.9041611932515117\n",
            "Round: 863 Weight: [2.40173396 1.26228861] Bias: -0.9042464333516487\n",
            "Round: 864 Weight: [2.40201545 1.26243888] Bias: -0.904331426975137\n",
            "Round: 865 Weight: [2.40229614 1.26258874] Bias: -0.90441617491646\n",
            "Round: 866 Weight: [2.40257603 1.26273817] Bias: -0.9045006779670526\n",
            "Round: 867 Weight: [2.40285514 1.26288719] Bias: -0.9045849369153168\n",
            "Round: 868 Weight: [2.40313345 1.26303578] Bias: -0.9046689525466359\n",
            "Round: 869 Weight: [2.40341097 1.26318395] Bias: -0.9047527256433888\n",
            "Round: 870 Weight: [2.40368771 1.26333171] Bias: -0.9048362569849645\n",
            "Round: 871 Weight: [2.40396366 1.26347905] Bias: -0.9049195473477765\n",
            "Round: 872 Weight: [2.40423883 1.26362598] Bias: -0.9050025975052769\n",
            "Round: 873 Weight: [2.40451323 1.26377249] Bias: -0.9050854082279706\n",
            "Round: 874 Weight: [2.40478684 1.2639186 ] Bias: -0.9051679802834292\n",
            "Round: 875 Weight: [2.40505968 1.26406429] Bias: -0.9052503144363049\n",
            "Round: 876 Weight: [2.40533176 1.26420957] Bias: -0.9053324114483449\n",
            "Round: 877 Weight: [2.40560306 1.26435444] Bias: -0.9054142720784043\n",
            "Round: 878 Weight: [2.40587359 1.26449891] Bias: -0.9054958970824606\n",
            "Round: 879 Weight: [2.40614336 1.26464297] Bias: -0.905577287213627\n",
            "Round: 880 Weight: [2.40641237 1.26478663] Bias: -0.9056584432221658\n",
            "Round: 881 Weight: [2.40668062 1.26492988] Bias: -0.9057393658555022\n",
            "Round: 882 Weight: [2.40694811 1.26507273] Bias: -0.9058200558582373\n",
            "Round: 883 Weight: [2.40721485 1.26521518] Bias: -0.9059005139721618\n",
            "Round: 884 Weight: [2.40748083 1.26535723] Bias: -0.9059807409362688\n",
            "Round: 885 Weight: [2.40774606 1.26549889] Bias: -0.9060607374867674\n",
            "Round: 886 Weight: [2.40801055 1.26564014] Bias: -0.9061405043570955\n",
            "Round: 887 Weight: [2.40827429 1.265781  ] Bias: -0.9062200422779326\n",
            "Round: 888 Weight: [2.40853728 1.26592147] Bias: -0.9062993519772133\n",
            "Round: 889 Weight: [2.40879954 1.26606154] Bias: -0.9063784341801395\n",
            "Round: 890 Weight: [2.40906105 1.26620122] Bias: -0.9064572896091936\n",
            "Round: 891 Weight: [2.40932183 1.2663405 ] Bias: -0.906535918984151\n",
            "Round: 892 Weight: [2.40958187 1.2664794 ] Bias: -0.9066143230220927\n",
            "Round: 893 Weight: [2.40984118 1.26661791] Bias: -0.9066925024374178\n",
            "Round: 894 Weight: [2.41009977 1.26675603] Bias: -0.9067704579418565\n",
            "Round: 895 Weight: [2.41035762 1.26689377] Bias: -0.9068481902444816\n",
            "Round: 896 Weight: [2.41061475 1.26703112] Bias: -0.9069257000517215\n",
            "Round: 897 Weight: [2.41087115 1.26716808] Bias: -0.907002988067372\n",
            "Round: 898 Weight: [2.41112684 1.26730466] Bias: -0.9070800549926091\n",
            "Round: 899 Weight: [2.4113818  1.26744087] Bias: -0.9071569015260005\n",
            "Round: 900 Weight: [2.41163605 1.26757669] Bias: -0.9072335283635178\n",
            "Round: 901 Weight: [2.41188959 1.26771213] Bias: -0.9073099361985486\n",
            "Round: 902 Weight: [2.41214241 1.26784719] Bias: -0.9073861257219085\n",
            "Round: 903 Weight: [2.41239452 1.26798187] Bias: -0.9074620976218525\n",
            "Round: 904 Weight: [2.41264592 1.26811618] Bias: -0.9075378525840871\n",
            "Round: 905 Weight: [2.41289662 1.26825012] Bias: -0.9076133912917821\n",
            "Round: 906 Weight: [2.41314662 1.26838368] Bias: -0.9076887144255819\n",
            "Round: 907 Weight: [2.41339591 1.26851686] Bias: -0.9077638226636171\n",
            "Round: 908 Weight: [2.4136445  1.26864968] Bias: -0.9078387166815164\n",
            "Round: 909 Weight: [2.4138924  1.26878212] Bias: -0.9079133971524176\n",
            "Round: 910 Weight: [2.4141396 1.2689142] Bias: -0.9079878647469791\n",
            "Round: 911 Weight: [2.41438611 1.26904591] Bias: -0.9080621201333913\n",
            "Round: 912 Weight: [2.41463192 1.26917725] Bias: -0.9081361639773876\n",
            "Round: 913 Weight: [2.41487705 1.26930822] Bias: -0.9082099969422558\n",
            "Round: 914 Weight: [2.41512149 1.26943883] Bias: -0.9082836196888492\n",
            "Round: 915 Weight: [2.41536525 1.26956908] Bias: -0.9083570328755973\n",
            "Round: 916 Weight: [2.41560833 1.26969896] Bias: -0.9084302371585175\n",
            "Round: 917 Weight: [2.41585072 1.26982848] Bias: -0.9085032331912251\n",
            "Round: 918 Weight: [2.41609244 1.26995764] Bias: -0.9085760216249449\n",
            "Round: 919 Weight: [2.41633347 1.27008644] Bias: -0.9086486031085217\n",
            "Round: 920 Weight: [2.41657384 1.27021489] Bias: -0.908720978288431\n",
            "Round: 921 Weight: [2.41681353 1.27034297] Bias: -0.9087931478087898\n",
            "Round: 922 Weight: [2.41705255 1.2704707 ] Bias: -0.9088651123113671\n",
            "Round: 923 Weight: [2.41729091 1.27059807] Bias: -0.9089368724355946\n",
            "Round: 924 Weight: [2.4175286  1.27072509] Bias: -0.9090084288185769\n",
            "Round: 925 Weight: [2.41776562 1.27085176] Bias: -0.9090797820951023\n",
            "Round: 926 Weight: [2.41800198 1.27097807] Bias: -0.909150932897653\n",
            "Round: 927 Weight: [2.41823768 1.27110404] Bias: -0.9092218818564155\n",
            "Round: 928 Weight: [2.41847273 1.27122965] Bias: -0.9092926295992906\n",
            "Round: 929 Weight: [2.41870711 1.27135492] Bias: -0.9093631767519039\n",
            "Round: 930 Weight: [2.41894085 1.27147983] Bias: -0.9094335239376159\n",
            "Round: 931 Weight: [2.41917393 1.2716044 ] Bias: -0.909503671777532\n",
            "Round: 932 Weight: [2.41940636 1.27172863] Bias: -0.9095736208905126\n",
            "Round: 933 Weight: [2.41963814 1.27185251] Bias: -0.9096433718931832\n",
            "Round: 934 Weight: [2.41986927 1.27197604] Bias: -0.909712925399944\n",
            "Round: 935 Weight: [2.42009977 1.27209924] Bias: -0.9097822820229797\n",
            "Round: 936 Weight: [2.42032961 1.27222209] Bias: -0.9098514423722702\n",
            "Round: 937 Weight: [2.42055882 1.2723446 ] Bias: -0.9099204070555992\n",
            "Round: 938 Weight: [2.42078739 1.27246677] Bias: -0.9099891766785646\n",
            "Round: 939 Weight: [2.42101532 1.2725886 ] Bias: -0.9100577518445881\n",
            "Round: 940 Weight: [2.42124262 1.2727101 ] Bias: -0.9101261331549246\n",
            "Round: 941 Weight: [2.42146929 1.27283125] Bias: -0.9101943212086717\n",
            "Round: 942 Weight: [2.42169532 1.27295208] Bias: -0.9102623166027796\n",
            "Round: 943 Weight: [2.42192073 1.27307256] Bias: -0.9103301199320599\n",
            "Round: 944 Weight: [2.42214551 1.27319272] Bias: -0.9103977317891957\n",
            "Round: 945 Weight: [2.42236966 1.27331254] Bias: -0.9104651527647504\n",
            "Round: 946 Weight: [2.42259319 1.27343203] Bias: -0.9105323834471772\n",
            "Round: 947 Weight: [2.42281609 1.27355119] Bias: -0.9105994244228285\n",
            "Round: 948 Weight: [2.42303838 1.27367002] Bias: -0.9106662762759646\n",
            "Round: 949 Weight: [2.42326005 1.27378852] Bias: -0.9107329395887634\n",
            "Round: 950 Weight: [2.42348111 1.27390669] Bias: -0.9107994149413291\n",
            "Round: 951 Weight: [2.42370155 1.27402454] Bias: -0.9108657029117014\n",
            "Round: 952 Weight: [2.42392137 1.27414206] Bias: -0.9109318040758645\n",
            "Round: 953 Weight: [2.42414059 1.27425925] Bias: -0.9109977190077558\n",
            "Round: 954 Weight: [2.4243592  1.27437612] Bias: -0.9110634482792753\n",
            "Round: 955 Weight: [2.4245772  1.27449267] Bias: -0.9111289924602939\n",
            "Round: 956 Weight: [2.42479459 1.2746089 ] Bias: -0.9111943521186624\n",
            "Round: 957 Weight: [2.42501139 1.2747248 ] Bias: -0.9112595278202203\n",
            "Round: 958 Weight: [2.42522758 1.27484039] Bias: -0.9113245201288047\n",
            "Round: 959 Weight: [2.42544317 1.27495566] Bias: -0.9113893296062584\n",
            "Round: 960 Weight: [2.42565816 1.2750706 ] Bias: -0.9114539568124389\n",
            "Round: 961 Weight: [2.42587256 1.27518523] Bias: -0.911518402305227\n",
            "Round: 962 Weight: [2.42608637 1.27529955] Bias: -0.9115826666405351\n",
            "Round: 963 Weight: [2.42629958 1.27541355] Bias: -0.9116467503723158\n",
            "Round: 964 Weight: [2.4265122  1.27552723] Bias: -0.9117106540525703\n",
            "Round: 965 Weight: [2.42672423 1.2756406 ] Bias: -0.9117743782313569\n",
            "Round: 966 Weight: [2.42693567 1.27575366] Bias: -0.9118379234567988\n",
            "Round: 967 Weight: [2.42714653 1.27586641] Bias: -0.9119012902750931\n",
            "Round: 968 Weight: [2.4273568  1.27597884] Bias: -0.9119644792305189\n",
            "Round: 969 Weight: [2.4275665  1.27609097] Bias: -0.912027490865445\n",
            "Round: 970 Weight: [2.42777561 1.27620279] Bias: -0.9120903257203384\n",
            "Round: 971 Weight: [2.42798414 1.27631429] Bias: -0.9121529843337728\n",
            "Round: 972 Weight: [2.4281921 1.2764255] Bias: -0.9122154672424357\n",
            "Round: 973 Weight: [2.42839948 1.27653639] Bias: -0.9122777749811376\n",
            "Round: 974 Weight: [2.42860629 1.27664698] Bias: -0.912339908082819\n",
            "Round: 975 Weight: [2.42881252 1.27675727] Bias: -0.9124018670785587\n",
            "Round: 976 Weight: [2.42901819 1.27686725] Bias: -0.9124636524975821\n",
            "Round: 977 Weight: [2.42922329 1.27697693] Bias: -0.9125252648672684\n",
            "Round: 978 Weight: [2.42942782 1.27708631] Bias: -0.9125867047131586\n",
            "Round: 979 Weight: [2.42963178 1.27719538] Bias: -0.9126479725589638\n",
            "Round: 980 Weight: [2.42983518 1.27730416] Bias: -0.9127090689265722\n",
            "Round: 981 Weight: [2.43003802 1.27741264] Bias: -0.9127699943360573\n",
            "Round: 982 Weight: [2.4302403  1.27752082] Bias: -0.9128307493056853\n",
            "Round: 983 Weight: [2.43044203 1.2776287 ] Bias: -0.9128913343519227\n",
            "Round: 984 Weight: [2.43064319 1.27773628] Bias: -0.9129517499894441\n",
            "Round: 985 Weight: [2.4308438  1.27784357] Bias: -0.9130119967311395\n",
            "Round: 986 Weight: [2.43104386 1.27795057] Bias: -0.913072075088122\n",
            "Round: 987 Weight: [2.43124336 1.27805727] Bias: -0.9131319855697353\n",
            "Round: 988 Weight: [2.43144232 1.27816368] Bias: -0.9131917286835605\n",
            "Round: 989 Weight: [2.43164072 1.27826979] Bias: -0.9132513049354243\n",
            "Round: 990 Weight: [2.43183858 1.27837562] Bias: -0.913310714829406\n",
            "Round: 991 Weight: [2.4320359  1.27848115] Bias: -0.9133699588678447\n",
            "Round: 992 Weight: [2.43223267 1.27858639] Bias: -0.9134290375513466\n",
            "Round: 993 Weight: [2.43242889 1.27869135] Bias: -0.9134879513787926\n",
            "Round: 994 Weight: [2.43262458 1.27879602] Bias: -0.9135467008473448\n",
            "Round: 995 Weight: [2.43281973 1.2789004 ] Bias: -0.9136052864524542\n",
            "Round: 996 Weight: [2.43301434 1.27900449] Bias: -0.9136637086878676\n",
            "Round: 997 Weight: [2.43320842 1.2791083 ] Bias: -0.9137219680456349\n",
            "Round: 998 Weight: [2.43340196 1.27921182] Bias: -0.9137800650161156\n",
            "Round: 999 Weight: [2.43359496 1.27931506] Bias: -0.9138380000879867\n",
            "[0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0.\n",
            " 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
            "actual Value\tpredicted values\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "1 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 1\n",
            "0 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 1\n",
            "0 \t\t 1\n",
            "1 \t\t 0\n",
            "0 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 1\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 1\n",
            "1 \t\t 1\n",
            "0 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 1\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 1\n",
            "0 \t\t 1\n",
            "0 \t\t 1\n",
            "1 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 1\n",
            "1 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 1\n",
            "0 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "1 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 1\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 1\n",
            "1 \t\t 0\n",
            "0 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 1\n",
            "0 \t\t 0\n",
            "0 \t\t 0\n",
            "0 \t\t 1\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 0\n",
            "1 \t\t 0\n",
            "0 \t\t 1\n",
            "Accuracy: 0.892\n",
            "Precision: 0.848\n",
            "Recall: 0.778\n",
            "[0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 1 0 1 0\n",
            " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 1 0 0 0 1 0]\n",
            "0.8916666666666667\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-ab0998c957e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;31m# Plot a graph of number of epochs vs training loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;31m# Get training and test loss histories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import torch\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/BuyComputer.csv')\n",
        "data.drop(columns=['User ID',],axis=1,inplace=True)\n",
        "data\n",
        "\n",
        "#Declare label as last column in the source file\n",
        "target = data.iloc[:, -1].values\n",
        "# print(target)\n",
        "\n",
        "#Declaring X as all columns excluding last\n",
        "features = data.iloc[:, :-1].values\n",
        "# print(features)\n",
        "\n",
        "# Splitting data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features,target, test_size = 0.30, random_state = 154)\n",
        "\n",
        "# Scaling data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "#Variabes to calculate sigmoid function\n",
        "y_pred = []\n",
        "len_x = len(X_train[0])\n",
        "w = []\n",
        "b = 0.2\n",
        "print(len_x)\n",
        "entries = len(X_train[:,0])\n",
        "\n",
        "for weights in range(len_x):\n",
        "    w.append(0)\n",
        "w\n",
        "\n",
        "dw = []\n",
        "db = 0\n",
        "J = 0\n",
        "alpha = 0.1\n",
        "\n",
        "# Sigmoid function\n",
        "def sigmoid(z):\n",
        "    return 1/(1 + np.exp(-z))\n",
        "\n",
        "#Prediction\n",
        "def predict(input):\n",
        "    z = np.dot(input, w) + b\n",
        "    h= sigmoid(z)\n",
        "    for i in range(len(h)):\n",
        "        if(h[i]>=0.5):\n",
        "            h[i]=1\n",
        "        else:\n",
        "            h[i]=0\n",
        "    return h\n",
        "\n",
        "#Loss function\n",
        "def loss_func(y, y1):\n",
        "    total_bce_loss = np.sum(-y * np.log(y1) - (1 - y) * np.log(1 - y1))\n",
        "    m = y.shape[0]\n",
        "    j = total_bce_loss /m\n",
        "    return j\n",
        "\n",
        "#Repeating the process 1000 times\n",
        "for i in range(1000):\n",
        "    z = np.dot(X_train, w) + b\n",
        "    y_pred = sigmoid(z)\n",
        "    l = loss_func(y_pred, y_train)\n",
        "    dw = np.dot((y_pred-y_train).T, X_train)/X_train.shape[0]\n",
        "    db = np.mean(y_pred-y_train)\n",
        "    w = w - alpha * dw\n",
        "    b = b - alpha* db\n",
        "    print(\"Round:\",i,\"Weight:\",w,\"Bias:\",b)\n",
        "\n",
        "#predicting the label\n",
        "y_pred=predict(X_train)\n",
        "print(y_pred)\n",
        "\n",
        "#print actual and predicted values in a table\n",
        "print(\"actual Value\\tpredicted values\")\n",
        "for i in range(len(y_test)):\n",
        "    print(y_test[i],\"\\t\\t\",int(y_pred[i]))\n",
        "\n",
        "# Calculating accuracy,precison,recall of prediction\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "# 3. What is the accuracy, precision and recall of the model?\n",
        "pred =predict(X_test)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, pred))\t\n",
        "print('Precision: %.3f' % precision_score(y_test,pred))\n",
        "print('Recall: %.3f' % recall_score(y_test,pred))\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logisticRegr = LogisticRegression()\n",
        "logisticRegr.fit(X_train, y_train)\n",
        "# a = logisticRegr.predict(X_test[0].reshape(1,-1))\n",
        "\n",
        "predictions = logisticRegr.predict(X_test)\n",
        "print(predictions)\n",
        "# print(y_test)\n",
        "\n",
        "# Use score method to get accuracy of model\n",
        "score = logisticRegr.score(X_test, y_test)\n",
        "print(score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "zIEpBwkUZzMH",
        "outputId": "725e8445-756e-4096-fe30-d8a56a40d149"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 1 0 1 0\n",
            " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0\n",
            " 0 0 0 0 1 1 0 0 0 0 1 1]\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-e081d5cbaca6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Get training and test loss histories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mtraining_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogisticRegr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogisticRegr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'history'"
          ]
        }
      ],
      "source": [
        "#Importing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "import math\n",
        "\n",
        "# reading the csv file, del 2 columns from the file, checking first few rows of the file\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/BuyComputer.csv\")\n",
        "\n",
        "dataset.drop(columns=['User ID',],axis=1,inplace=True)\n",
        "label = dataset.iloc[:,-1].values\n",
        "X = dataset.drop(\"Purchased\" ,axis= 1)\n",
        "\n",
        "# print(X)\n",
        "# Splitting data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_Train, X_Test, y_Train, y_Test = train_test_split(X,label, test_size = 0.40, random_state = 154)\n",
        "\n",
        "# Scaaling data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "\n",
        "X_Train = sc.fit_transform(X_Train)\n",
        "X_Test = sc.transform(X_Test)\n",
        "\n",
        "# print(X_Train)\n",
        "X_Train=torch.from_numpy(X_Train)\n",
        "y_Train=torch.from_numpy(y_Train)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logisticRegr = LogisticRegression(random_state = 154)\n",
        "logisticRegr.fit(X_Train, y_Train)\n",
        "\n",
        "predictions = logisticRegr.predict(X_Test)\n",
        "print(predictions)\n",
        "\n",
        "# # 4. Plot a graph of number of epochs vs training loss.\n",
        "\n",
        "# # Get training and test loss histories\n",
        "# training_loss = logisticRegr.\n",
        "# test_loss = logisticRegr.history['val_loss']\n",
        "\n",
        "# # Create count of the number of epochs\n",
        "# epoch_count = range(1, len(training_loss) + 1)\n",
        "\n",
        "# # Visualize loss history\n",
        "# plt.plot(epoch_count, training_loss, 'r--')\n",
        "# plt.plot(epoch_count, test_loss, 'b-')\n",
        "# plt.legend(['Training Loss', 'Test Loss'])\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.show();\n",
        "\n",
        "# Use the model to identify if a person whose age is 28 years and his/her estimated salary is 76000 will purchase a computer?\n",
        "pred = logisticRegr.predict([[28,76000]])\n",
        "print(pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqRV3ajg8wTD",
        "outputId": "e0b8c45b-c66c-4dbd-a9ab-a2b38a2aa397"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "7a451522cbdcd215ccca4cd695db6edceccf10814386aa801974aa9e14ca5f5a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}